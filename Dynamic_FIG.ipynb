{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eb75068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import cross_validate\n",
    "import matplotlib.pyplot as plt\n",
    "import imodels\n",
    "from imodels import FIGSClassifier\n",
    "from imodels import FIGSRegressor\n",
    "from scipy.stats import bernoulli, binom\n",
    "import sklearn.datasets\n",
    "from sklearn import datasets\n",
    "from sklearn import tree\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, RegressorMixin\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import plot_tree, DecisionTreeClassifier\n",
    "from sklearn.utils import check_X_y, check_array\n",
    "from sklearn.utils.validation import _check_sample_weight\n",
    "from copy import deepcopy\n",
    "from imodels.tree.viz_utils import extract_sklearn_tree_from_figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f0b1ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature: int = None, threshold: int = None,\n",
    "                 value=None, value_sklearn=None, idxs=None, is_root: bool = False, left=None,\n",
    "                 impurity: float = None, impurity_reduction: float = None, tree_num: int = None, node_id: int = None,\n",
    "                 right=None):\n",
    "        \"\"\"Node class for splitting\n",
    "        \"\"\"\n",
    "\n",
    "        # split or linear\n",
    "        self.is_root = is_root\n",
    "        self.idxs = idxs\n",
    "        self.tree_num = tree_num\n",
    "        self.node_id = None\n",
    "        self.feature = feature\n",
    "        self.impurity = impurity\n",
    "        self.impurity_reduction = impurity_reduction\n",
    "        self.value_sklearn = value_sklearn\n",
    "\n",
    "        # different meanings\n",
    "        self.value = value  # for split this is mean, for linear this is weight\n",
    "\n",
    "        # split-specific\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.left_temp = None\n",
    "        self.right_temp = None\n",
    "\n",
    "    def setattrs(self, **kwargs):\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "    def __str__(self):\n",
    "        if self.is_root:\n",
    "            return f'X_{self.feature} <= {self.threshold:0.3f} (Tree #{self.tree_num} root)'\n",
    "        elif self.left is None and self.right is None:\n",
    "            return f'Val: {self.value[0][0]:0.3f} (leaf)'\n",
    "        else:\n",
    "            return f'X_{self.feature} <= {self.threshold:0.3f} (split)'\n",
    "\n",
    "    def print_root(self, y):\n",
    "        try:\n",
    "            one_count = pd.Series(y).value_counts()[1.0]\n",
    "        except KeyError:\n",
    "            one_count = 0\n",
    "        one_proportion = f' {one_count}/{y.shape[0]} ({round(100 * one_count / y.shape[0], 2)}%)'\n",
    "\n",
    "        if self.is_root:\n",
    "            return f'X_{self.feature} <= {self.threshold:0.3f}' + one_proportion\n",
    "        elif self.left is None and self.right is None:\n",
    "            return f'ΔRisk = {self.value[0][0]:0.2f}' + one_proportion\n",
    "        else:\n",
    "            return f'X_{self.feature} <= {self.threshold:0.3f}' + one_proportion\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ca8cbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class D_FIGS(FIGSRegressor):\n",
    "    # Needs to store the old X and y\n",
    "\n",
    "    # feature_phases = {1 : (X, y, model), 2 : (X_phase2, y, model)}\n",
    "    feature_phases = None\n",
    "\n",
    "    def __init__(self, max_rules: int = 12, min_impurity_decrease: float = 0.0, random_state=None,\n",
    "                 max_features: str = None, feature_phases=None):\n",
    "        super().__init__(max_rules, min_impurity_decrease, random_state, max_features)\n",
    "        self.feature_phases = feature_phases\n",
    "\n",
    "    def check_phase(self, old_phases, new_phase):\n",
    "        for i in range(len(old_phases)):\n",
    "            '''\n",
    "            phase 2 features can be available (not NA) only if all phase 1 features are available\n",
    "            '''\n",
    "            if np.isnan(old_phases).any() and not np.isnan(new_phase).all():\n",
    "                raise ValueError('A very specific bad thing happened.')\n",
    "\n",
    "    '''\n",
    "    add the new phase features to X, delete samples that has NaN in new_phase potentially refit the model?\n",
    "    '''\n",
    "    '''\n",
    "    def add_new_phase(self, new_phase):\n",
    "        self.check_phase(self.old_phase, new_phase)\n",
    "        concatenated_phase = np.concatenate((self.old_phase, new_phase), axis=0)\n",
    "        old_phase = concatenated_phase\n",
    "\n",
    "        # after getting the copied model and potential splits, change the idx\n",
    "        for node in self.potential_splits:\n",
    "            new_idx = []\n",
    "            for i in range(len(node.idx)):\n",
    "                new_feature = new_phase[node.idx[i]]  # new phase features for the particular sample i\n",
    "                if not np.isnan(new_feature).any():  # If the new phase has no nan\n",
    "                    new_idx.append(node.idx[i])\n",
    "            node.idx = new_idx  # The leaves that we can potentially split on now contain only samples with new_phase'''\n",
    "\n",
    "    def fit_phase_1(self, X, y):\n",
    "        self.fit(X, y)\n",
    "        # Store a deep copy of the whole model for easier prediction use in the future\n",
    "        self.feature_phases = {}\n",
    "        self.feature_phases[1] = (X, y, deepcopy(self))\n",
    "        return self\n",
    "\n",
    "    '''\n",
    "    This will infer the newly added features from the last stored X\n",
    "    This function only delete samples for a newly generated root!!!\n",
    "    '''\n",
    "\n",
    "    def remove_na_samples(self, X):\n",
    "        phase_idx = len(self.feature_phases)  # infer the number of phase from the dict\n",
    "        prev_phase = self.feature_phases[phase_idx][0]\n",
    "        new_phase = X[:, len(prev_phase[0]):]\n",
    "        cur_idxs = np.ones(X.shape[0], dtype=bool)\n",
    "        for i in range(len(cur_idxs)):\n",
    "            if cur_idxs[i]:\n",
    "                new_feature = new_phase[i]\n",
    "                # new phase features for the particular sample i\n",
    "                # If the new phase has nan, which means it is not valid and should be false in the idxs\n",
    "                if np.isnan(new_feature).any():\n",
    "                    cur_idxs[i] = False\n",
    "        return cur_idxs\n",
    "\n",
    "    def update_potential_splits(self, X, y, potential_splits, y_predictions_per_tree, y_residuals_per_tree):\n",
    "\n",
    "        for tree_num_ in range(len(self.trees_)):\n",
    "            y_predictions_per_tree[tree_num_] = self._predict_tree(self.trees_[tree_num_], X)\n",
    "        y_predictions_per_tree[-1] = np.zeros(X.shape[0])  # dummy 0 preds for possible new trees\n",
    "\n",
    "        # update residuals for each tree\n",
    "        # -1 is key for potential new tree\n",
    "        for tree_num_ in list(range(len(self.trees_))) + [-1]:\n",
    "            y_residuals_per_tree[tree_num_] = deepcopy(y)\n",
    "\n",
    "            # subtract predictions of all other trees\n",
    "            for tree_num_other_ in range(len(self.trees_)):\n",
    "                if not tree_num_other_ == tree_num_:\n",
    "                    y_residuals_per_tree[tree_num_] -= y_predictions_per_tree[tree_num_other_]\n",
    "\n",
    "        # recompute all impurities + update potential_split children\n",
    "        potential_splits_new = []\n",
    "        for potential_split in potential_splits:\n",
    "            y_target = y_residuals_per_tree[potential_split.tree_num]\n",
    "\n",
    "            # re-calculate the best split\n",
    "            potential_split_updated = self._construct_node_with_stump(X=X,\n",
    "                                                                      y=y_target,\n",
    "                                                                      idxs=potential_split.idxs,\n",
    "                                                                      tree_num=potential_split.tree_num,\n",
    "                                                                      max_features=self.max_features)\n",
    "\n",
    "            # need to preserve certain attributes from before (value at this split + is_root)\n",
    "            # value may change because residuals may have changed, but we want it to store the value from before\n",
    "            potential_split.setattrs(\n",
    "                feature=potential_split_updated.feature,\n",
    "                threshold=potential_split_updated.threshold,\n",
    "                impurity_reduction=potential_split_updated.impurity_reduction,\n",
    "                left_temp=potential_split_updated.left_temp,\n",
    "                right_temp=potential_split_updated.right_temp,\n",
    "            )\n",
    "\n",
    "            # this is a valid split\n",
    "            if potential_split.impurity_reduction is not None:\n",
    "                potential_splits_new.append(potential_split)\n",
    "        sorted_potential_splits_new = sorted(potential_splits_new, key=lambda x: x.impurity_reduction)\n",
    "        return sorted_potential_splits_new, y_predictions_per_tree, y_residuals_per_tree\n",
    "    \n",
    "    def fit_phase_n(self, X, y, max_rules=15):\n",
    "        phase_idx = len(self.feature_phases)  # infer the number of phase from the dict\n",
    "        prev_phase = self.feature_phases[phase_idx][0]\n",
    "        new_phase = X[:, len(prev_phase[0]):]\n",
    "        all_leaves = []\n",
    "        for node in self.trees_:\n",
    "            all_leaves += self.get_leaves(node)\n",
    "        # Right now, we are only removing samples that do not have the newest phase in the leaves, not their ancestors\n",
    "        for node in all_leaves:\n",
    "            for i in range(len(node.idxs)):\n",
    "                if node.idxs[i]:\n",
    "                    new_feature = new_phase[i]\n",
    "                    # new phase features for the particular sample i\n",
    "                    # If the new phase has nan, which means it is not valid and should be false in the idxs\n",
    "                    if np.isnan(new_feature).any():\n",
    "                        node.idxs[i] = False\n",
    "\n",
    "        self.extend_trees(X, y, all_leaves, max_rules=max_rules)\n",
    "        self.feature_phases[phase_idx + 1] = (X, y, deepcopy(self))\n",
    "        return self\n",
    "    \n",
    "    def extend_trees(self, X, y, all_leaves, max_rules=15):\n",
    "        # Need to add max_rules each time so that it's bigger than the complexity\n",
    "        self.max_rules += max_rules\n",
    "        potential_splits = []\n",
    "        y_predictions_per_tree = {}  # predictions for each tree\n",
    "        y_residuals_per_tree = {}  # based on predictions above\n",
    "        first_extend = True\n",
    "\n",
    "        # Get all the leaves from the previous model\n",
    "        # for node in self.trees_:\n",
    "        #    all_leaves += self.get_leaves(node)\n",
    "        # iterate through all the leaves and split them on the new feature\n",
    "        count = 0\n",
    "        for leaf in all_leaves:\n",
    "            count += 1\n",
    "            b = np.isnan(X[leaf.idxs]).any()\n",
    "            if len(X[leaf.idxs]) == 0:\n",
    "                continue\n",
    "            potential_split = self._construct_node_with_stump(X, y, idxs=leaf.idxs, tree_num=leaf.tree_num,\n",
    "                                                              max_features=None)\n",
    "            if potential_split.impurity_reduction is not None:\n",
    "                # Update the leaves on the previous model\n",
    "                leaf.setattrs(feature=potential_split.feature,\n",
    "                              threshold=potential_split.threshold,\n",
    "                              impurity_reduction=potential_split.impurity_reduction,\n",
    "                              left_temp=potential_split.left_temp,\n",
    "                              right_temp=potential_split.right_temp,\n",
    "                              tree_num=potential_split.tree_num,\n",
    "                              impurity=potential_split.impurity,\n",
    "                              idxs=potential_split.idxs)\n",
    "                # Add to the potential splits, and do the same fitting process as in the fig\n",
    "                potential_splits.append(leaf)\n",
    "        '''\n",
    "        phase_idx = len(self.feature_phases)  # infer the number of phase from the dict\n",
    "        prev_phase = self.feature_phases[phase_idx][0]\n",
    "        new_phase = X[:, len(prev_phase[0]):]\n",
    "        cur_idxs = np.ones(X.shape[0], dtype=bool)\n",
    "        for i in range(len(cur_idxs)):\n",
    "            if cur_idxs[i]:\n",
    "                new_feature = new_phase[i]\n",
    "                # new phase features for the particular sample i\n",
    "                # If the new phase has nan, which means it is not valid and should be false in the idxs\n",
    "                if np.isnan(new_feature).any():\n",
    "                    cur_idxs[i] = False\n",
    "        '''\n",
    "        cur_idxs = self.remove_na_samples(X)\n",
    "        node_new_root = Node(is_root=True, idxs=cur_idxs,\n",
    "                             tree_num=-1)\n",
    "        potential_splits.append(node_new_root)\n",
    "        # //TODO DEBUG\n",
    "        '''\n",
    "        ## Add new root\n",
    "        phase_idx = len(self.feature_phases)  # infer the number of phase from the dict\n",
    "        prev_phase = self.feature_phases[phase_idx][0]\n",
    "        new_phase = X[:, len(prev_phase[0]):]\n",
    "        cur_idxs = np.ones(X.shape[0], dtype=bool)\n",
    "        for i in range(len(cur_idxs)):\n",
    "            if cur_idxs[i]:\n",
    "                new_feature = new_phase[i]\n",
    "                # new phase features for the particular sample i\n",
    "                # If the new phase has nan, which means it is not valid and should be false in the idxs\n",
    "                if np.isnan(new_feature).any():\n",
    "                    cur_idxs[i] = False\n",
    "        node_new_root = Node(is_root=True, idxs=cur_idxs,\n",
    "                             tree_num=-1)\n",
    "        potential_splits.append(node_new_root)\n",
    "\n",
    "\n",
    "        for tree_num_ in range(len(self.trees_)):\n",
    "            y_predictions_per_tree[tree_num_] = self._predict_tree(self.trees_[tree_num_], X)\n",
    "        y_predictions_per_tree[-1] = np.zeros(X.shape[0])  # dummy 0 preds for possible new trees\n",
    "\n",
    "        # update residuals for each tree\n",
    "        # -1 is key for potential new tree\n",
    "        for tree_num_ in list(range(len(self.trees_))) + [-1]:\n",
    "            y_residuals_per_tree[tree_num_] = deepcopy(y)\n",
    "\n",
    "            # subtract predictions of all other trees\n",
    "            for tree_num_other_ in range(len(self.trees_)):\n",
    "                if not tree_num_other_ == tree_num_:\n",
    "                    y_residuals_per_tree[tree_num_] -= y_predictions_per_tree[tree_num_other_]\n",
    "\n",
    "        # recompute all impurities + update potential_split children\n",
    "        potential_splits_new = []\n",
    "        for potential_split in potential_splits:\n",
    "            y_target = y_residuals_per_tree[potential_split.tree_num]\n",
    "\n",
    "            # re-calculate the best split\n",
    "            potential_split_updated = self._construct_node_with_stump(X=X,\n",
    "                                                                      y=y_target,\n",
    "                                                                      idxs=potential_split.idxs,\n",
    "                                                                      tree_num=potential_split.tree_num,\n",
    "                                                                      max_features=self.max_features)\n",
    "\n",
    "            # need to preserve certain attributes from before (value at this split + is_root)\n",
    "            # value may change because residuals may have changed, but we want it to store the value from before\n",
    "            potential_split.setattrs(\n",
    "                feature=potential_split_updated.feature,\n",
    "                threshold=potential_split_updated.threshold,\n",
    "                impurity_reduction=potential_split_updated.impurity_reduction,\n",
    "                left_temp=potential_split_updated.left_temp,\n",
    "                right_temp=potential_split_updated.right_temp,\n",
    "            )\n",
    "\n",
    "            # this is a valid split\n",
    "            if potential_split.impurity_reduction is not None:\n",
    "                potential_splits_new.append(potential_split)\n",
    "        '''\n",
    "        # sort so the largest impurity reduction comes last (should probs make this a heap later)\n",
    "        potential_splits, y_predictions_per_tree, y_residuals_per_tree = self.update_potential_splits(X,\n",
    "                                                                                                      y,\n",
    "                                                                                                      potential_splits,\n",
    "                                                                                                      y_predictions_per_tree,\n",
    "                                                                                                      y_residuals_per_tree)\n",
    "        # //TODO DEBUG END\n",
    "        # for i in potential_splits:\n",
    "        #    print(i.impurity_reduction)\n",
    "\n",
    "        # original: line 253\n",
    "        # potential_splits = sorted(potential_splits, key=lambda x: x.impurity_reduction)\n",
    "\n",
    "        finished = False\n",
    "        while len(potential_splits) > 0 and not finished:\n",
    "            # print('potential_splits', [str(s) for s in potential_splits])\n",
    "            split_node = potential_splits.pop()  # get node with max impurity_reduction (since it's sorted)\n",
    "\n",
    "            # don't split on node\n",
    "            if split_node.impurity_reduction < self.min_impurity_decrease:\n",
    "                finished = True\n",
    "                break\n",
    "\n",
    "            # split on node\n",
    "            self.complexity_ += 1\n",
    "\n",
    "            # if added a tree root\n",
    "            if split_node.is_root:\n",
    "                # start a new tree\n",
    "                self.trees_.append(split_node)\n",
    "\n",
    "                # update tree_num\n",
    "                for node_ in [split_node, split_node.left_temp, split_node.right_temp]:\n",
    "                    if node_ is not None:\n",
    "                        node_.tree_num = len(self.trees_) - 1\n",
    "\n",
    "                # add new root potential node\n",
    "                '''\n",
    "                phase_idx = len(self.feature_phases)  # infer the number of phase from the dict\n",
    "                prev_phase = self.feature_phases[phase_idx][0]\n",
    "                new_phase = X[:, len(prev_phase[0]):]\n",
    "                cur_idxs = np.ones(X.shape[0], dtype=bool)\n",
    "                for i in range(len(cur_idxs)):\n",
    "                    if cur_idxs[i]:\n",
    "                        new_feature = new_phase[i]\n",
    "                        # new phase features for the particular sample i\n",
    "                        # If the new phase has nan, which means it is not valid and should be false in the idxs\n",
    "                        if np.isnan(new_feature).any():\n",
    "                            cur_idxs[i] = False\n",
    "                '''\n",
    "                cur_idxs = self.remove_na_samples(X)\n",
    "                node_new_root = Node(is_root=True, idxs=cur_idxs,\n",
    "                                     tree_num=-1)\n",
    "                potential_splits.append(node_new_root)\n",
    "\n",
    "            # add children to potential splits\n",
    "            # assign left_temp, right_temp to be proper children\n",
    "            # (basically adds them to tree in predict method)\n",
    "            split_node.setattrs(left=split_node.left_temp, right=split_node.right_temp)\n",
    "\n",
    "            # add children to potential_splits\n",
    "            potential_splits.append(split_node.left)\n",
    "            potential_splits.append(split_node.right)\n",
    "\n",
    "            '''\n",
    "            Debug, replace with function\n",
    "            # update predictions for altered tree\n",
    "            for tree_num_ in range(len(self.trees_)):\n",
    "                y_predictions_per_tree[tree_num_] = self._predict_tree(self.trees_[tree_num_], X)\n",
    "            y_predictions_per_tree[-1] = np.zeros(X.shape[0])  # dummy 0 preds for possible new trees\n",
    "\n",
    "            # update residuals for each tree\n",
    "            # -1 is key for potential new tree\n",
    "            for tree_num_ in list(range(len(self.trees_))) + [-1]:\n",
    "                y_residuals_per_tree[tree_num_] = deepcopy(y)\n",
    "\n",
    "                # subtract predictions of all other trees\n",
    "                for tree_num_other_ in range(len(self.trees_)):\n",
    "                    if not tree_num_other_ == tree_num_:\n",
    "                        y_residuals_per_tree[tree_num_] -= y_predictions_per_tree[tree_num_other_]\n",
    "\n",
    "            # recompute all impurities + update potential_split children\n",
    "            potential_splits_new = []\n",
    "            for potential_split in potential_splits:\n",
    "                y_target = y_residuals_per_tree[potential_split.tree_num]\n",
    "\n",
    "                # re-calculate the best split\n",
    "                potential_split_updated = self._construct_node_with_stump(X=X,\n",
    "                                                                          y=y_target,\n",
    "                                                                          idxs=potential_split.idxs,\n",
    "                                                                          tree_num=potential_split.tree_num,\n",
    "                                                                          max_features=self.max_features)\n",
    "\n",
    "                # need to preserve certain attributes from before (value at this split + is_root)\n",
    "                # value may change because residuals may have changed, but we want it to store the value from before\n",
    "                potential_split.setattrs(\n",
    "                    feature=potential_split_updated.feature,\n",
    "                    threshold=potential_split_updated.threshold,\n",
    "                    impurity_reduction=potential_split_updated.impurity_reduction,\n",
    "                    left_temp=potential_split_updated.left_temp,\n",
    "                    right_temp=potential_split_updated.right_temp,\n",
    "                )\n",
    "\n",
    "                # this is a valid split\n",
    "                if potential_split.impurity_reduction is not None:\n",
    "                    potential_splits_new.append(potential_split)\n",
    "\n",
    "            # sort so largest impurity reduction comes last (should probs make this a heap later)\n",
    "            '''\n",
    "\n",
    "            # potential_splits = sorted(potential_splits_new, key=lambda x: x.impurity_reduction)\n",
    "            potential_splits, y_predictions_per_tree, y_residuals_per_tree = self.update_potential_splits(X,\n",
    "                                                                                                          y,\n",
    "                                                                                                          potential_splits,\n",
    "                                                                                                          y_predictions_per_tree,\n",
    "                                                                                                          y_residuals_per_tree)\n",
    "            if self.max_rules is not None and self.complexity_ >= self.max_rules:\n",
    "                finished = True\n",
    "                break\n",
    "\n",
    "            # annotate final tree with node_id and value_sklearn\n",
    "        for tree_ in self.trees_:\n",
    "            node_counter = iter(range(0, int(1e06)))\n",
    "\n",
    "            def _annotate_node(node: Node, X, y):\n",
    "                if node is None:\n",
    "                    return\n",
    "\n",
    "                # TODO does not incorporate sample weights\n",
    "                value_counts = pd.Series(y).value_counts()\n",
    "                try:\n",
    "                    neg_count = value_counts[0.0]\n",
    "                except KeyError:\n",
    "                    neg_count = 0\n",
    "\n",
    "                try:\n",
    "                    pos_count = value_counts[1.0]\n",
    "                except KeyError:\n",
    "                    pos_count = 0\n",
    "\n",
    "                value_sklearn = np.array([neg_count, pos_count], dtype=float)\n",
    "\n",
    "                node.setattrs(node_id=next(node_counter), value_sklearn=value_sklearn)\n",
    "\n",
    "                idxs_left = X[:, node.feature] <= node.threshold\n",
    "                _annotate_node(node.left, X[idxs_left], y[idxs_left])\n",
    "                _annotate_node(node.right, X[~idxs_left], y[~idxs_left])\n",
    "\n",
    "            _annotate_node(tree_, X, y)\n",
    "            return self\n",
    "\n",
    "    def get_leaves(self, root):\n",
    "        s1 = []\n",
    "        s2 = []\n",
    "        s1.append(root)\n",
    "        while len(s1) != 0:\n",
    "            curr = s1.pop()\n",
    "            if curr.left:\n",
    "                s1.append(curr.left)\n",
    "            if curr.right:\n",
    "                s1.append(curr.right)\n",
    "            elif not curr.left and not curr.right:\n",
    "                s2.append(curr)\n",
    "        return s2\n",
    "\n",
    "    def predict_phase_i(self, X, phase):\n",
    "        model = self.feature_phases[phase][2]\n",
    "        return model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bbdc8b",
   "metadata": {},
   "source": [
    "$y = \\mathbb{1}[x_1 < 0.5 and x_2 < 0.5] + \\mathbb{1}[x_3 < 0.5 and x_4 < 0.5]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0163051d",
   "metadata": {},
   "source": [
    "# No nan value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a09d8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no nan\n",
    "sample_num = 50000\n",
    "X_fig_large = np.random.uniform(0, 1, (sample_num, 4))\n",
    "y_fig_large = np.array([0.0] * sample_num)\n",
    "for idx in range(len(X_fig_large)) :\n",
    "    x1_x2 = X_fig_large[idx][0] < 0.5 and X_fig_large[idx][1] < 0.5\n",
    "    x3_x4 = X_fig_large[idx][2] < 0.5 and X_fig_large[idx][3] < 0.5\n",
    "    if x1_x2 and x3_x4:\n",
    "        y_fig_large[idx] = 2.0\n",
    "    elif x1_x2 or x3_x4:\n",
    "        y_fig_large[idx] = 1.0\n",
    "X_fig_large_1 = X_fig_large[:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d692784",
   "metadata": {},
   "outputs": [],
   "source": [
    "l, w = X_fig_large.shape\n",
    "mean = 0\n",
    "var = 0.01\n",
    "sigma = np.sqrt(var)\n",
    "n = np.random.normal(loc=mean,\n",
    "                     scale=sigma,\n",
    "                    size=(l,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "772ab0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fig_large_noise = X_fig_large + n\n",
    "X_fig_large_1_noise = X_fig_large_noise[:, :2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14813c55",
   "metadata": {},
   "source": [
    "### FIG result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ea2b5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_fig = FIGSRegressor(max_rules=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df3886b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>&gt; ------------------------------\n",
       "&gt; FIGS-Fast Interpretable Greedy-Tree Sums:\n",
       "&gt; \tPredictions are made by summing the &quot;Val&quot; reached by traversing each tree\n",
       "&gt; ------------------------------\n",
       "X_1 &lt;= 0.500 (Tree #0 root)\n",
       "\tX_0 &lt;= 0.499 (split)\n",
       "\t\tVal: 1.111 (leaf)\n",
       "\t\tVal: 0.327 (leaf)\n",
       "\tVal: 0.286 (leaf)\n",
       "\n",
       "\t+\n",
       "X_2 &lt;= 0.489 (Tree #1 root)\n",
       "\tX_3 &lt;= 0.512 (split)\n",
       "\t\tVal: 0.599 (leaf)\n",
       "\t\tVal: -0.188 (leaf)\n",
       "\tVal: -0.209 (leaf)\n",
       "</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FIGSRegressor</label><div class=\"sk-toggleable__content\"><pre>&gt; ------------------------------\n",
       "&gt; FIGS-Fast Interpretable Greedy-Tree Sums:\n",
       "&gt; \tPredictions are made by summing the &quot;Val&quot; reached by traversing each tree\n",
       "&gt; ------------------------------\n",
       "X_1 &lt;= 0.500 (Tree #0 root)\n",
       "\tX_0 &lt;= 0.499 (split)\n",
       "\t\tVal: 1.111 (leaf)\n",
       "\t\tVal: 0.327 (leaf)\n",
       "\tVal: 0.286 (leaf)\n",
       "\n",
       "\t+\n",
       "X_2 &lt;= 0.489 (Tree #1 root)\n",
       "\tX_3 &lt;= 0.512 (split)\n",
       "\t\tVal: 0.599 (leaf)\n",
       "\t\tVal: -0.188 (leaf)\n",
       "\tVal: -0.209 (leaf)\n",
       "</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "FIGSRegressor(max_rules=4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_fig.fit(X_fig_large_noise, y_fig_large)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24b0c4b",
   "metadata": {},
   "source": [
    "### D-FIG result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bac560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_fig = D_FIGS(max_rules=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "badfc60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>&gt; ------------------------------\n",
       "&gt; FIGS-Fast Interpretable Greedy-Tree Sums:\n",
       "&gt; \tPredictions are made by summing the &quot;Val&quot; reached by traversing each tree\n",
       "&gt; ------------------------------\n",
       "X_1 &lt;= 0.500 (Tree #0 root)\n",
       "\tX_0 &lt;= 0.499 (split)\n",
       "\t\tVal: 1.111 (leaf)\n",
       "\t\tVal: 0.327 (leaf)\n",
       "\tVal: 0.286 (leaf)\n",
       "</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">D_FIGS</label><div class=\"sk-toggleable__content\"><pre>&gt; ------------------------------\n",
       "&gt; FIGS-Fast Interpretable Greedy-Tree Sums:\n",
       "&gt; \tPredictions are made by summing the &quot;Val&quot; reached by traversing each tree\n",
       "&gt; ------------------------------\n",
       "X_1 &lt;= 0.500 (Tree #0 root)\n",
       "\tX_0 &lt;= 0.499 (split)\n",
       "\t\tVal: 1.111 (leaf)\n",
       "\t\tVal: 0.327 (leaf)\n",
       "\tVal: 0.286 (leaf)\n",
       "</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "D_FIGS(feature_phases={1: (array([[0.66419487, 0.19796503],\n",
       "       [0.53268384, 0.62993613],\n",
       "       [0.73603072, 0.04663398],\n",
       "       ...,\n",
       "       [0.59886778, 0.49085245],\n",
       "       [0.12100196, 0.99298586],\n",
       "       [0.5485777 , 0.14369666]]),\n",
       "                           array([0., 0., 0., ..., 0., 1., 1.]),\n",
       "                           D_FIGS(feature_phases={}, max_rules=2))},\n",
       "       max_rules=2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_fig.fit_phase_1(X_fig_large_1_noise, y_fig_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41f7bedd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>&gt; ------------------------------\n",
       "&gt; FIGS-Fast Interpretable Greedy-Tree Sums:\n",
       "&gt; \tPredictions are made by summing the &quot;Val&quot; reached by traversing each tree\n",
       "&gt; ------------------------------\n",
       "X_1 &lt;= 0.500 (Tree #0 root)\n",
       "\tX_0 &lt;= 0.499 (split)\n",
       "\t\tVal: 1.111 (leaf)\n",
       "\t\tVal: 0.327 (leaf)\n",
       "\tVal: 0.286 (leaf)\n",
       "\n",
       "\t+\n",
       "X_2 &lt;= 0.489 (Tree #1 root)\n",
       "\tX_3 &lt;= 0.512 (split)\n",
       "\t\tVal: 0.599 (leaf)\n",
       "\t\tVal: -0.188 (leaf)\n",
       "\tVal: -0.209 (leaf)\n",
       "</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">D_FIGS</label><div class=\"sk-toggleable__content\"><pre>&gt; ------------------------------\n",
       "&gt; FIGS-Fast Interpretable Greedy-Tree Sums:\n",
       "&gt; \tPredictions are made by summing the &quot;Val&quot; reached by traversing each tree\n",
       "&gt; ------------------------------\n",
       "X_1 &lt;= 0.500 (Tree #0 root)\n",
       "\tX_0 &lt;= 0.499 (split)\n",
       "\t\tVal: 1.111 (leaf)\n",
       "\t\tVal: 0.327 (leaf)\n",
       "\tVal: 0.286 (leaf)\n",
       "\n",
       "\t+\n",
       "X_2 &lt;= 0.489 (Tree #1 root)\n",
       "\tX_3 &lt;= 0.512 (split)\n",
       "\t\tVal: 0.599 (leaf)\n",
       "\t\tVal: -0.188 (leaf)\n",
       "\tVal: -0.209 (leaf)\n",
       "</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "D_FIGS(feature_phases={1: (array([[0.66419487, 0.19796503],\n",
       "       [0.53268384, 0.62993613],\n",
       "       [0.73603072, 0.04663398],\n",
       "       ...,\n",
       "       [0.59886778, 0.49085245],\n",
       "       [0.12100196, 0.99298586],\n",
       "       [0.5485777 , 0.14369666]]),\n",
       "                           array([0., 0., 0., ..., 0., 1., 1.]),\n",
       "                           D_FIGS(feature_phases={}, max_rules=2)),\n",
       "                       2: (array([[ 0.66419487,  0.19796503,  0.05705136,  0.93576751],\n",
       "       [ 0.53268384,  0.62993613,  1.03967043,  0.684614...\n",
       "       [ 0.5485777 ,  0.14369666,  0.09357027,  0.86219446]]),\n",
       "                           array([0., 0., 0., ..., 0., 1., 1.]),\n",
       "                           D_FIGS(feature_phases={1: (array([[0.66419487, 0.19796503],\n",
       "       [0.53268384, 0.62993613],\n",
       "       [0.73603072, 0.04663398],\n",
       "       ...,\n",
       "       [0.59886778, 0.49085245],\n",
       "       [0.12100196, 0.99298586],\n",
       "       [0.5485777 , 0.14369666]]),\n",
       "                                                      array([0., 0., 0., ..., 0., 1., 1.]),\n",
       "                                                      D_FIGS(feature_phases={},\n",
       "                                                             max_rules=2))},\n",
       "                                  max_rules=4))},\n",
       "       max_rules=4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_fig.fit_phase_n(X_fig_large_noise, y_fig_large, max_rules=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f0e52b",
   "metadata": {},
   "source": [
    "# With nan value, D-fig only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "518a9782",
   "metadata": {},
   "outputs": [],
   "source": [
    "#With nan\n",
    "sample_num = 50000\n",
    "X_fig_large_na = np.random.uniform(0, 1, (sample_num, 4))\n",
    "y_fig_large_na = np.array([0.0] * sample_num)\n",
    "for idx in range(len(X_fig_large_na)) :\n",
    "    x1_x2 = X_fig_large_na[idx][0] < 0.5 and X_fig_large_na[idx][1] < 0.5\n",
    "    x3_x4 = X_fig_large_na[idx][2] < 0.5 and X_fig_large_na[idx][3] < 0.5\n",
    "    prob = np.random.uniform(0, 1)\n",
    "    if prob <= 0.8:\n",
    "        X_fig_large_na[idx][2] = np.nan\n",
    "        X_fig_large_na[idx][3] = np.nan\n",
    "        x3_x4 = False\n",
    "    if x1_x2 and x3_x4:\n",
    "        y_fig_large_na[idx] = 2.0\n",
    "    elif x1_x2 or x3_x4:\n",
    "        y_fig_large_na[idx] = 1.0\n",
    "X_fig_large_1_na = X_fig_large_na[:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c82e151",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fig_large_na_noise = X_fig_large_na + n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d47da55",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fig_large_1_na_noise = X_fig_large_na_noise[:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "280570a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_fig = D_FIGS(max_rules=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "716222cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>&gt; ------------------------------\n",
       "&gt; FIGS-Fast Interpretable Greedy-Tree Sums:\n",
       "&gt; \tPredictions are made by summing the &quot;Val&quot; reached by traversing each tree\n",
       "&gt; ------------------------------\n",
       "X_0 &lt;= 0.500 (Tree #0 root)\n",
       "\tX_1 &lt;= 0.500 (split)\n",
       "\t\tVal: 1.052 (leaf)\n",
       "\t\tVal: 0.053 (leaf)\n",
       "\tVal: 0.050 (leaf)\n",
       "</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">D_FIGS</label><div class=\"sk-toggleable__content\"><pre>&gt; ------------------------------\n",
       "&gt; FIGS-Fast Interpretable Greedy-Tree Sums:\n",
       "&gt; \tPredictions are made by summing the &quot;Val&quot; reached by traversing each tree\n",
       "&gt; ------------------------------\n",
       "X_0 &lt;= 0.500 (Tree #0 root)\n",
       "\tX_1 &lt;= 0.500 (split)\n",
       "\t\tVal: 1.052 (leaf)\n",
       "\t\tVal: 0.053 (leaf)\n",
       "\tVal: 0.050 (leaf)\n",
       "</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "D_FIGS(feature_phases={1: (array([[0.12977861, 0.51268928],\n",
       "       [0.46056058, 0.67673613],\n",
       "       [0.94488741, 0.88358604],\n",
       "       ...,\n",
       "       [0.87718695, 0.30731018],\n",
       "       [0.83295155, 0.8795118 ],\n",
       "       [0.95854278, 0.4367938 ]]),\n",
       "                           array([0., 0., 0., ..., 0., 0., 1.]),\n",
       "                           D_FIGS(feature_phases={}, max_rules=2))},\n",
       "       max_rules=2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_fig.fit_phase_1(X_fig_large_1_na, y_fig_large_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbb043c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>&gt; ------------------------------\n",
       "&gt; FIGS-Fast Interpretable Greedy-Tree Sums:\n",
       "&gt; \tPredictions are made by summing the &quot;Val&quot; reached by traversing each tree\n",
       "&gt; ------------------------------\n",
       "X_0 &lt;= 0.500 (Tree #0 root)\n",
       "\tX_1 &lt;= 0.500 (split)\n",
       "\t\tVal: 1.052 (leaf)\n",
       "\t\tVal: 0.053 (leaf)\n",
       "\tVal: 0.050 (leaf)\n",
       "\n",
       "\t+\n",
       "X_3 &lt;= 0.499 (Tree #1 root)\n",
       "\tX_2 &lt;= 0.500 (split)\n",
       "\t\tVal: 0.949 (leaf)\n",
       "\t\tVal: -0.051 (leaf)\n",
       "\tVal: -0.051 (leaf)\n",
       "</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">D_FIGS</label><div class=\"sk-toggleable__content\"><pre>&gt; ------------------------------\n",
       "&gt; FIGS-Fast Interpretable Greedy-Tree Sums:\n",
       "&gt; \tPredictions are made by summing the &quot;Val&quot; reached by traversing each tree\n",
       "&gt; ------------------------------\n",
       "X_0 &lt;= 0.500 (Tree #0 root)\n",
       "\tX_1 &lt;= 0.500 (split)\n",
       "\t\tVal: 1.052 (leaf)\n",
       "\t\tVal: 0.053 (leaf)\n",
       "\tVal: 0.050 (leaf)\n",
       "\n",
       "\t+\n",
       "X_3 &lt;= 0.499 (Tree #1 root)\n",
       "\tX_2 &lt;= 0.500 (split)\n",
       "\t\tVal: 0.949 (leaf)\n",
       "\t\tVal: -0.051 (leaf)\n",
       "\tVal: -0.051 (leaf)\n",
       "</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "D_FIGS(feature_phases={1: (array([[0.12977861, 0.51268928],\n",
       "       [0.46056058, 0.67673613],\n",
       "       [0.94488741, 0.88358604],\n",
       "       ...,\n",
       "       [0.87718695, 0.30731018],\n",
       "       [0.83295155, 0.8795118 ],\n",
       "       [0.95854278, 0.4367938 ]]),\n",
       "                           array([0., 0., 0., ..., 0., 0., 1.]),\n",
       "                           D_FIGS(feature_phases={}, max_rules=2)),\n",
       "                       2: (array([[0.12977861, 0.51268928,        nan,        nan],\n",
       "       [0.46056058, 0.67673613,        nan,        nan],\n",
       "       [0.94488741, 0.88358604,        na...\n",
       "       [0.95854278, 0.4367938 , 0.03829485, 0.11976037]]),\n",
       "                           array([0., 0., 0., ..., 0., 0., 1.]),\n",
       "                           D_FIGS(feature_phases={1: (array([[0.12977861, 0.51268928],\n",
       "       [0.46056058, 0.67673613],\n",
       "       [0.94488741, 0.88358604],\n",
       "       ...,\n",
       "       [0.87718695, 0.30731018],\n",
       "       [0.83295155, 0.8795118 ],\n",
       "       [0.95854278, 0.4367938 ]]),\n",
       "                                                      array([0., 0., 0., ..., 0., 0., 1.]),\n",
       "                                                      D_FIGS(feature_phases={},\n",
       "                                                             max_rules=2))},\n",
       "                                  max_rules=4))},\n",
       "       max_rules=4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_fig.fit_phase_n(X_fig_large_na, y_fig_large_na, max_rules=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e04740",
   "metadata": {},
   "source": [
    "### Predict using phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eeeeed47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04954719, 0.04954719, 0.04954719, 1.05191604, 1.05191604,\n",
       "       1.05191604, 0.04954719])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_fig.predict_phase_i([[1, 1, 1, 1], [1, 0, 0, 0], [1, 1, 0, 0], [0, 0, 0, 0], [0, 0, 1, 1], [0, 0, 1, 0], [1, 0, 1, 0]], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c3b117",
   "metadata": {},
   "source": [
    "### Predict using phase 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2aacebec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.22708951e-03,  9.98525505e-01,  9.98525505e-01,  2.00089436e+00,\n",
       "        1.00114176e+00,  1.00089675e+00, -1.47209934e-03])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_fig.predict_phase_i([[1, 1, 1, 1], [1, 0, 0, 0], [1, 1, 0, 0], [0, 0, 0, 0], [0, 0, 1, 1], [0, 0, 1, 0], [1, 0, 1, 0]], 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
