<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<section id="section-intro">
<p>Modified from <a href="https://github.com/RaczeQ/scikit-learn-C4.5-tree-classifier">https://github.com/RaczeQ/scikit-learn-C4.5-tree-classifier</a>
References</p>
<hr>
<p>.. [1] <a href="https://en.wikipedia.org/wiki/Decision_tree_learning">https://en.wikipedia.org/wiki/Decision_tree_learning</a>
.. [2] <a href="https://en.wikipedia.org/wiki/C4.5_algorithm">https://en.wikipedia.org/wiki/C4.5_algorithm</a></p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Modified from https://github.com/RaczeQ/scikit-learn-C4.5-tree-classifier
References
----------
.. [1] https://en.wikipedia.org/wiki/Decision_tree_learning
.. [2] https://en.wikipedia.org/wiki/C4.5_algorithm
&#34;&#34;&#34;
import copy
from copy import deepcopy
from typing import List
from xml.dom import minidom
from xml.etree import ElementTree as ET

import numpy as np
import pandas as pd
from sklearn.base import BaseEstimator, ClassifierMixin
from sklearn.model_selection import cross_val_score
from sklearn.utils.validation import check_array, check_is_fitted, check_X_y
from imodels.util.arguments import check_fit_arguments

from ..c45_tree.c45_utils import decision, is_numeric_feature, gain, gain_ratio, get_best_split, \
    set_as_leaf_node
from ...util.data_util import get_clean_dataset


def _add_label(node, label):
    if hasattr(node, &#34;labels&#34;):
        node.labels.append(label)
        return
    node.labels = [label]
    return


def _get_next_node(children, att):
    for child in children:
        is_equal = child.getAttribute(&#34;flag&#34;) == &#34;m&#34; and child.getAttribute(&#34;feature&#34;) == att
        is_less_than = child.getAttribute(&#34;flag&#34;) == &#34;l&#34; and float(att) &lt; float(child.getAttribute(&#34;feature&#34;))
        is_greater_than = child.getAttribute(&#34;flag&#34;) == &#34;r&#34; and float(att) &gt;= float(child.getAttribute(&#34;feature&#34;))
        if is_equal or is_less_than or is_greater_than:
            return child


def shrink_node(node, reg_param, parent_val, parent_num, cum_sum, scheme, constant):
    &#34;&#34;&#34;Shrink the tree
    &#34;&#34;&#34;

    is_leaf = not node.hasChildNodes()
    # if self.prediction_task == &#39;regression&#39;:
    val = node.nodeValue
    is_root = parent_val is None and parent_num is None
    n_samples = len(node.labels) if (scheme != &#34;leaf_based&#34; or is_root) else parent_num

    if is_root:
        val_new = val

    else:
        reg_term = reg_param if scheme == &#34;constant&#34; else reg_param / parent_num

        val_new = (val - parent_val) / (1 + reg_term)

    cum_sum += val_new

    if is_leaf:
        if scheme == &#34;leaf_based&#34;:
            v = constant + (val - constant) / (1 + reg_param / node.n_obs)
            node.nodeValue = v
        else:
            node.nodeValue = cum_sum

    else:
        for c in node.childNodes:
            shrink_node(c, reg_param, val, parent_num=n_samples, cum_sum=cum_sum, scheme=scheme, constant=constant)

    return node


def _add_label(node, label):
    if hasattr(node, &#34;labels&#34;):
        node.labels.append(label)
        return
    node.labels = [label]
    return


def _get_next_node(children, att):
    for child in children:
        is_equal = child.getAttribute(&#34;flag&#34;) == &#34;m&#34; and child.getAttribute(&#34;feature&#34;) == att
        is_less_than = child.getAttribute(&#34;flag&#34;) == &#34;l&#34; and float(att) &lt; float(child.getAttribute(&#34;feature&#34;))
        is_greater_than = child.getAttribute(&#34;flag&#34;) == &#34;r&#34; and float(att) &gt;= float(child.getAttribute(&#34;feature&#34;))
        if is_equal or is_less_than or is_greater_than:
            return child


def shrink_node(node, reg_param, parent_val, parent_num, cum_sum, scheme, constant):
    &#34;&#34;&#34;Shrink the tree
    &#34;&#34;&#34;

    is_leaf = not node.hasChildNodes()
    # if self.prediction_task == &#39;regression&#39;:
    val = node.nodeValue
    is_root = parent_val is None and parent_num is None
    n_samples = len(node.labels) if (scheme != &#34;leaf_based&#34; or is_root) else parent_num

    if is_root:
        val_new = val

    else:
        reg_term = reg_param if scheme == &#34;constant&#34; else reg_param / parent_num

        val_new = (val - parent_val) / (1 + reg_term)

    cum_sum += val_new

    if is_leaf:
        if scheme == &#34;leaf_based&#34;:
            v = constant + (val - constant) / (1 + reg_param / node.n_obs)
            node.nodeValue = v
        else:
            node.nodeValue = cum_sum

    else:
        for c in node.childNodes:
            shrink_node(c, reg_param, val, parent_num=n_samples, cum_sum=cum_sum, scheme=scheme, constant=constant)

    return node


class C45TreeClassifier(BaseEstimator, ClassifierMixin):
    &#34;&#34;&#34;A C4.5 tree classifier.

    Parameters
    ----------
    max_rules : int, optional (default=None)
        Maximum number of split nodes allowed in the tree
    &#34;&#34;&#34;

    def __init__(self, max_rules: int = None):
        super().__init__()
        self.max_rules = max_rules

    def fit(self, X, y, feature_names: str = None):
        self.complexity_ = 0
        # X, y = check_X_y(X, y)
        X, y, feature_names = check_fit_arguments(self, X, y, feature_names)
        self.resultType = type(y[0])
        if feature_names is None:
            self.feature_names = [f&#39;X_{x}&#39; for x in range(X.shape[1])]
        else:
            # only include alphanumeric chars / replace spaces with underscores
            self.feature_names = [&#39;&#39;.join([i for i in x if i.isalnum()]).replace(&#39; &#39;, &#39;_&#39;)
                                  for x in feature_names]
            self.feature_names = [
                &#39;X_&#39; + x if x[0].isdigit()
                else x
                for x in self.feature_names
            ]

        assert len(self.feature_names) == X.shape[1]

        data = [[] for i in range(len(self.feature_names))]
        categories = []

        for i in range(len(X)):
            categories.append(str(y[i]))
            for j in range(len(self.feature_names)):
                data[j].append(X[i][j])
        root = ET.Element(&#39;GreedyTree&#39;)
        self.grow_tree(data, categories, root, self.feature_names)  # adds to root
        self.tree_ = ET.tostring(root, encoding=&#34;unicode&#34;)
        # print(&#39;self.tree_&#39;, self.tree_)
        self.dom_ = minidom.parseString(self.tree_)
        return self

    def impute_nodes(self, X, y):
        &#34;&#34;&#34;
        Returns
        ---
        the leaf by which this sample would be classified
        &#34;&#34;&#34;
        source_node = self.root
        for i in range(len(y)):
            sample, label = X[i, ...], y[i]
            _add_label(source_node, label)
            nodes = [source_node]
            while len(nodes) &gt; 0:
                node = nodes.pop()
                if not node.hasChildNodes():
                    continue
                else:
                    att_name = node.firstChild.nodeName
                    if att_name != &#34;#text&#34;:
                        att = sample[self.feature_names.index(att_name)]
                        next_node = _get_next_node(node.childNodes, att)
                    else:
                        next_node = node.firstChild
                    _add_label(next_node, label)
                    nodes.append(next_node)

        self._calc_probs(source_node)
        # self.dom_.childNodes[0] = source_node
        # self.tree_.source = source_node

    def _calc_probs(self, node):
        node.nodeValue = np.mean(node.labels)
        if not node.hasChildNodes():
            return
        for c in node.childNodes:
            self._calc_probs(c)

    def raw_preds(self, X):
        check_is_fitted(self, [&#39;tree_&#39;, &#39;resultType&#39;, &#39;feature_names&#39;])
        X = check_array(X)
        if isinstance(X, pd.DataFrame):
            X = deepcopy(X)
            X.columns = self.feature_names
        root = self.root
        prediction = []
        for i in range(X.shape[0]):
            answerlist = decision(root, X[i], self.feature_names, 1)
            answerlist = sorted(answerlist.items(), key=lambda x: x[1], reverse=True)
            answer = answerlist[0][0]
            # prediction.append(self.resultType(answer))
            prediction.append(float(answer))

        return np.array(prediction)

    def predict(self, X):
        raw_preds = self.raw_preds(X)
        return (raw_preds &gt; np.ones_like(raw_preds) * 0.5).astype(int)

    def predict_proba(self, X):
        raw_preds = self.raw_preds(X)
        return np.vstack((1 - raw_preds, raw_preds)).transpose()

    def __str__(self):
        check_is_fitted(self, [&#39;tree_&#39;])
        return self.dom_.toprettyxml(newl=&#34;\r\n&#34;)

    def grow_tree(self, X_t: List[list], y_str: List[str], parent, attrs_names):
        &#34;&#34;&#34;
        Parameters
        ----------
        X_t: List[list]
            input data transposed (num_features x num_observations)
        y_str: List[str]
            outcome represented as strings

        parent
        attrs_names

        &#34;&#34;&#34;
        # check that y contains more than 1 distinct value
        if len(set(y_str)) &gt; 1:
            split = []

            # loop over features and build up potential splits
            for i in range(len(X_t)):
                if set(X_t[i]) == set(&#34;?&#34;):
                    split.append(0)
                else:
                    if is_numeric_feature(X_t[i]):
                        split.append(gain(y_str, X_t[i]))
                    else:
                        split.append(gain_ratio(y_str, X_t[i]))

            # no good split, return child node
            if max(split) == 0:
                set_as_leaf_node(parent, y_str)

            # there is a good split
            else:
                index_selected = split.index(max(split))
                name_selected = str(attrs_names[index_selected])
                self.complexity_ += 1
                if is_numeric_feature(X_t[index_selected]):
                    # split on this point
                    split_point = get_best_split(y_str, X_t[index_selected])

                    # build up children nodes
                    r_child_X = [[] for i in range(len(X_t))]
                    r_child_y = []
                    l_child_X = [[] for i in range(len(X_t))]
                    l_child_y = []
                    for i in range(len(y_str)):
                        if not X_t[index_selected][i] == &#34;?&#34;:
                            if float(X_t[index_selected][i]) &lt; float(split_point):
                                l_child_y.append(y_str[i])
                                for j in range(len(X_t)):
                                    l_child_X[j].append(X_t[j][i])
                            else:
                                r_child_y.append(y_str[i])
                                for j in range(len(X_t)):
                                    r_child_X[j].append(X_t[j][i])

                    # grow child nodes as well
                    if len(l_child_y) &gt; 0 and len(r_child_y) &gt; 0 and (
                            self.max_rules is None or
                            self.complexity_ &lt;= self.max_rules
                    ):
                        p_l = float(len(l_child_y)) / (len(X_t[index_selected]) - X_t[index_selected].count(&#34;?&#34;))
                        son = ET.SubElement(parent, name_selected,
                                            {&#39;feature&#39;: str(split_point), &#34;flag&#34;: &#34;l&#34;, &#34;p&#34;: str(round(p_l, 3))})
                        self.grow_tree(l_child_X, l_child_y, son, attrs_names)
                        son = ET.SubElement(parent, name_selected,
                                            {&#39;feature&#39;: str(split_point), &#34;flag&#34;: &#34;r&#34;, &#34;p&#34;: str(round(1 - p_l, 3))})
                        self.grow_tree(r_child_X, r_child_y, son, attrs_names)
                    else:
                        num_max = 0
                        for cat in set(y_str):
                            num_cat = y_str.count(cat)
                            if num_cat &gt; num_max:
                                num_max = num_cat
                                most_cat = cat
                        parent.text = most_cat
                else:
                    # split on non-numeric variable (e.g. categorical)
                    # create a leaf for each unique value
                    for k in set(X_t[index_selected]):
                        if not k == &#34;?&#34; and (
                                self.max_rules is None or
                                self.complexity_ &lt;= self.max_rules
                        ):
                            child_X = [[] for i in range(len(X_t))]
                            child_y = []
                            for i in range(len(y_str)):
                                if X_t[index_selected][i] == k:
                                    child_y.append(y_str[i])
                                    for j in range(len(X_t)):
                                        child_X[j].append(X_t[j][i])
                            son = ET.SubElement(parent, name_selected, {
                                &#39;feature&#39;: k, &#34;flag&#34;: &#34;m&#34;,
                                &#39;p&#39;: str(round(
                                    float(len(child_y)) / (
                                            len(X_t[index_selected]) - X_t[index_selected].count(&#34;?&#34;)),
                                    3))})
                            self.grow_tree(child_X, child_y, son, attrs_names)
        else:
            parent.text = y_str[0]

    @property
    def root(self):
        return self.dom_.childNodes[0]


class HSC45TreeClassifier(BaseEstimator):
    def __init__(self, estimator_: C45TreeClassifier, reg_param: float = 1, shrinkage_scheme_: str = &#39;node_based&#39;):
        &#34;&#34;&#34;
        Params
        ------
        reg_param: float
            Higher is more regularization (can be arbitrarily large, should not be &lt; 0)

        shrinkage_scheme: str
            Experimental: Used to experiment with different forms of shrinkage. options are:
                (i) node_based shrinks based on number of samples in parent node
                (ii) leaf_based only shrinks leaf nodes based on number of leaf samples
                (iii) constant shrinks every node by a constant lambda
        &#34;&#34;&#34;
        super().__init__()
        self.reg_param = reg_param
        # print(&#39;est&#39;, estimator_)
        self.estimator_ = estimator_
        self.shrinkage_scheme_ = shrinkage_scheme_

    def _calc_probs(self, node):
        self.estimator_._calc_probs(node)

    def impute_nodes(self, X, y):
        self.estimator_.impute_nodes(X, y)

    def shrink_tree(self):
        shrink_node(self.estimator_.root, self.reg_param, None, None, 0, self.shrinkage_scheme_, 0)

    def predict_proba(self, X):
        return self.estimator_.predict_proba(X)

    def fit(self, *args, **kwargs):
        X = kwargs[&#39;X&#39;] if &#34;X&#34; in kwargs else args[0]
        y = kwargs[&#39;y&#39;] if &#34;y&#34; in kwargs else args[1]
        if not hasattr(self.estimator_, &#34;dom_&#34;):
            self.estimator_.fit(X, y)
        self.impute_nodes(X, y)
        self.shrink_tree()

    def predict(self, X):
        return self.estimator_.predict(X)

    @property
    def complexity_(self):
        return self.estimator_.complexity_


class HSC45TreeClassifierCV(HSC45TreeClassifier):
    def __init__(self, estimator_: C45TreeClassifier,
                 reg_param_list: List[float] = [0.1, 1, 10, 50, 100, 500], shrinkage_scheme_: str = &#39;node_based&#39;,
                 cv: int = 3, scoring=&#39;accuracy&#39;, *args, **kwargs):
        &#34;&#34;&#34;Note: args, kwargs are not used but left so that imodels-experiments can still pass redundant args
        &#34;&#34;&#34;
        super().__init__(estimator_, reg_param=None)
        self.reg_param_list = np.array(reg_param_list)
        self.cv = cv
        self.scoring = scoring
        self.shrinkage_scheme_ = shrinkage_scheme_
        # print(&#39;estimator&#39;, self.estimator_,
        #       &#39;checks.check_is_fitted(estimator)&#39;, checks.check_is_fitted(self.estimator_))
        # if checks.check_is_fitted(self.estimator_):
        #     raise Warning(&#39;Passed an already fitted estimator,&#39;
        #                   &#39;but shrinking not applied until fit method is called.&#39;)

    def fit(self, X, y, *args, **kwargs):
        self.scores_ = []

        for reg_param in self.reg_param_list:
            est = HSC45TreeClassifier(copy.deepcopy(self.estimator_), reg_param)
            cv_scores = cross_val_score(est, X, y, cv=self.cv, scoring=self.scoring)
            self.scores_.append(np.mean(cv_scores))
        self.reg_param = self.reg_param_list[np.argmax(self.scores_)]
        super().fit(X=X, y=y)


if __name__ == &#39;__main__&#39;:
    X, y, feature_names = get_clean_dataset(&#39;ionosphere&#39;, data_source=&#39;pmlb&#39;)
    m = C45TreeClassifier(max_rules=3)
    m.fit(X, y)
    s_m = HSC45TreeClassifier(estimator_=m)
    s_m.fit(X, y)
    preds = s_m.predict_proba(X)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="imodels.tree.c45_tree.c45_tree.shrink_node"><code class="name flex">
<span>def <span class="ident">shrink_node</span></span>(<span>node, reg_param, parent_val, parent_num, cum_sum, scheme, constant)</span>
</code></dt>
<dd>
<div class="desc"><p>Shrink the tree</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def shrink_node(node, reg_param, parent_val, parent_num, cum_sum, scheme, constant):
    &#34;&#34;&#34;Shrink the tree
    &#34;&#34;&#34;

    is_leaf = not node.hasChildNodes()
    # if self.prediction_task == &#39;regression&#39;:
    val = node.nodeValue
    is_root = parent_val is None and parent_num is None
    n_samples = len(node.labels) if (scheme != &#34;leaf_based&#34; or is_root) else parent_num

    if is_root:
        val_new = val

    else:
        reg_term = reg_param if scheme == &#34;constant&#34; else reg_param / parent_num

        val_new = (val - parent_val) / (1 + reg_term)

    cum_sum += val_new

    if is_leaf:
        if scheme == &#34;leaf_based&#34;:
            v = constant + (val - constant) / (1 + reg_param / node.n_obs)
            node.nodeValue = v
        else:
            node.nodeValue = cum_sum

    else:
        for c in node.childNodes:
            shrink_node(c, reg_param, val, parent_num=n_samples, cum_sum=cum_sum, scheme=scheme, constant=constant)

    return node</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="imodels.tree.c45_tree.c45_tree.C45TreeClassifier"><code class="flex name class">
<span>class <span class="ident">C45TreeClassifier</span></span>
<span>(</span><span>max_rules: int = None)</span>
</code></dt>
<dd>
<div class="desc"><p>A C4.5 tree classifier.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>max_rules</code></strong> :&ensp;<code>int</code>, optional <code>(default=None)</code></dt>
<dd>Maximum number of split nodes allowed in the tree</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class C45TreeClassifier(BaseEstimator, ClassifierMixin):
    &#34;&#34;&#34;A C4.5 tree classifier.

    Parameters
    ----------
    max_rules : int, optional (default=None)
        Maximum number of split nodes allowed in the tree
    &#34;&#34;&#34;

    def __init__(self, max_rules: int = None):
        super().__init__()
        self.max_rules = max_rules

    def fit(self, X, y, feature_names: str = None):
        self.complexity_ = 0
        # X, y = check_X_y(X, y)
        X, y, feature_names = check_fit_arguments(self, X, y, feature_names)
        self.resultType = type(y[0])
        if feature_names is None:
            self.feature_names = [f&#39;X_{x}&#39; for x in range(X.shape[1])]
        else:
            # only include alphanumeric chars / replace spaces with underscores
            self.feature_names = [&#39;&#39;.join([i for i in x if i.isalnum()]).replace(&#39; &#39;, &#39;_&#39;)
                                  for x in feature_names]
            self.feature_names = [
                &#39;X_&#39; + x if x[0].isdigit()
                else x
                for x in self.feature_names
            ]

        assert len(self.feature_names) == X.shape[1]

        data = [[] for i in range(len(self.feature_names))]
        categories = []

        for i in range(len(X)):
            categories.append(str(y[i]))
            for j in range(len(self.feature_names)):
                data[j].append(X[i][j])
        root = ET.Element(&#39;GreedyTree&#39;)
        self.grow_tree(data, categories, root, self.feature_names)  # adds to root
        self.tree_ = ET.tostring(root, encoding=&#34;unicode&#34;)
        # print(&#39;self.tree_&#39;, self.tree_)
        self.dom_ = minidom.parseString(self.tree_)
        return self

    def impute_nodes(self, X, y):
        &#34;&#34;&#34;
        Returns
        ---
        the leaf by which this sample would be classified
        &#34;&#34;&#34;
        source_node = self.root
        for i in range(len(y)):
            sample, label = X[i, ...], y[i]
            _add_label(source_node, label)
            nodes = [source_node]
            while len(nodes) &gt; 0:
                node = nodes.pop()
                if not node.hasChildNodes():
                    continue
                else:
                    att_name = node.firstChild.nodeName
                    if att_name != &#34;#text&#34;:
                        att = sample[self.feature_names.index(att_name)]
                        next_node = _get_next_node(node.childNodes, att)
                    else:
                        next_node = node.firstChild
                    _add_label(next_node, label)
                    nodes.append(next_node)

        self._calc_probs(source_node)
        # self.dom_.childNodes[0] = source_node
        # self.tree_.source = source_node

    def _calc_probs(self, node):
        node.nodeValue = np.mean(node.labels)
        if not node.hasChildNodes():
            return
        for c in node.childNodes:
            self._calc_probs(c)

    def raw_preds(self, X):
        check_is_fitted(self, [&#39;tree_&#39;, &#39;resultType&#39;, &#39;feature_names&#39;])
        X = check_array(X)
        if isinstance(X, pd.DataFrame):
            X = deepcopy(X)
            X.columns = self.feature_names
        root = self.root
        prediction = []
        for i in range(X.shape[0]):
            answerlist = decision(root, X[i], self.feature_names, 1)
            answerlist = sorted(answerlist.items(), key=lambda x: x[1], reverse=True)
            answer = answerlist[0][0]
            # prediction.append(self.resultType(answer))
            prediction.append(float(answer))

        return np.array(prediction)

    def predict(self, X):
        raw_preds = self.raw_preds(X)
        return (raw_preds &gt; np.ones_like(raw_preds) * 0.5).astype(int)

    def predict_proba(self, X):
        raw_preds = self.raw_preds(X)
        return np.vstack((1 - raw_preds, raw_preds)).transpose()

    def __str__(self):
        check_is_fitted(self, [&#39;tree_&#39;])
        return self.dom_.toprettyxml(newl=&#34;\r\n&#34;)

    def grow_tree(self, X_t: List[list], y_str: List[str], parent, attrs_names):
        &#34;&#34;&#34;
        Parameters
        ----------
        X_t: List[list]
            input data transposed (num_features x num_observations)
        y_str: List[str]
            outcome represented as strings

        parent
        attrs_names

        &#34;&#34;&#34;
        # check that y contains more than 1 distinct value
        if len(set(y_str)) &gt; 1:
            split = []

            # loop over features and build up potential splits
            for i in range(len(X_t)):
                if set(X_t[i]) == set(&#34;?&#34;):
                    split.append(0)
                else:
                    if is_numeric_feature(X_t[i]):
                        split.append(gain(y_str, X_t[i]))
                    else:
                        split.append(gain_ratio(y_str, X_t[i]))

            # no good split, return child node
            if max(split) == 0:
                set_as_leaf_node(parent, y_str)

            # there is a good split
            else:
                index_selected = split.index(max(split))
                name_selected = str(attrs_names[index_selected])
                self.complexity_ += 1
                if is_numeric_feature(X_t[index_selected]):
                    # split on this point
                    split_point = get_best_split(y_str, X_t[index_selected])

                    # build up children nodes
                    r_child_X = [[] for i in range(len(X_t))]
                    r_child_y = []
                    l_child_X = [[] for i in range(len(X_t))]
                    l_child_y = []
                    for i in range(len(y_str)):
                        if not X_t[index_selected][i] == &#34;?&#34;:
                            if float(X_t[index_selected][i]) &lt; float(split_point):
                                l_child_y.append(y_str[i])
                                for j in range(len(X_t)):
                                    l_child_X[j].append(X_t[j][i])
                            else:
                                r_child_y.append(y_str[i])
                                for j in range(len(X_t)):
                                    r_child_X[j].append(X_t[j][i])

                    # grow child nodes as well
                    if len(l_child_y) &gt; 0 and len(r_child_y) &gt; 0 and (
                            self.max_rules is None or
                            self.complexity_ &lt;= self.max_rules
                    ):
                        p_l = float(len(l_child_y)) / (len(X_t[index_selected]) - X_t[index_selected].count(&#34;?&#34;))
                        son = ET.SubElement(parent, name_selected,
                                            {&#39;feature&#39;: str(split_point), &#34;flag&#34;: &#34;l&#34;, &#34;p&#34;: str(round(p_l, 3))})
                        self.grow_tree(l_child_X, l_child_y, son, attrs_names)
                        son = ET.SubElement(parent, name_selected,
                                            {&#39;feature&#39;: str(split_point), &#34;flag&#34;: &#34;r&#34;, &#34;p&#34;: str(round(1 - p_l, 3))})
                        self.grow_tree(r_child_X, r_child_y, son, attrs_names)
                    else:
                        num_max = 0
                        for cat in set(y_str):
                            num_cat = y_str.count(cat)
                            if num_cat &gt; num_max:
                                num_max = num_cat
                                most_cat = cat
                        parent.text = most_cat
                else:
                    # split on non-numeric variable (e.g. categorical)
                    # create a leaf for each unique value
                    for k in set(X_t[index_selected]):
                        if not k == &#34;?&#34; and (
                                self.max_rules is None or
                                self.complexity_ &lt;= self.max_rules
                        ):
                            child_X = [[] for i in range(len(X_t))]
                            child_y = []
                            for i in range(len(y_str)):
                                if X_t[index_selected][i] == k:
                                    child_y.append(y_str[i])
                                    for j in range(len(X_t)):
                                        child_X[j].append(X_t[j][i])
                            son = ET.SubElement(parent, name_selected, {
                                &#39;feature&#39;: k, &#34;flag&#34;: &#34;m&#34;,
                                &#39;p&#39;: str(round(
                                    float(len(child_y)) / (
                                            len(X_t[index_selected]) - X_t[index_selected].count(&#34;?&#34;)),
                                    3))})
                            self.grow_tree(child_X, child_y, son, attrs_names)
        else:
            parent.text = y_str[0]

    @property
    def root(self):
        return self.dom_.childNodes[0]</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>sklearn.base.BaseEstimator</li>
<li>sklearn.utils._metadata_requests._MetadataRequester</li>
<li>sklearn.base.ClassifierMixin</li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="imodels.tree.c45_tree.c45_tree.C45TreeClassifier.root"><code class="name">var <span class="ident">root</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def root(self):
    return self.dom_.childNodes[0]</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="imodels.tree.c45_tree.c45_tree.C45TreeClassifier.fit"><code class="name flex">
<span>def <span class="ident">fit</span></span>(<span>self, X, y, feature_names: str = None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fit(self, X, y, feature_names: str = None):
    self.complexity_ = 0
    # X, y = check_X_y(X, y)
    X, y, feature_names = check_fit_arguments(self, X, y, feature_names)
    self.resultType = type(y[0])
    if feature_names is None:
        self.feature_names = [f&#39;X_{x}&#39; for x in range(X.shape[1])]
    else:
        # only include alphanumeric chars / replace spaces with underscores
        self.feature_names = [&#39;&#39;.join([i for i in x if i.isalnum()]).replace(&#39; &#39;, &#39;_&#39;)
                              for x in feature_names]
        self.feature_names = [
            &#39;X_&#39; + x if x[0].isdigit()
            else x
            for x in self.feature_names
        ]

    assert len(self.feature_names) == X.shape[1]

    data = [[] for i in range(len(self.feature_names))]
    categories = []

    for i in range(len(X)):
        categories.append(str(y[i]))
        for j in range(len(self.feature_names)):
            data[j].append(X[i][j])
    root = ET.Element(&#39;GreedyTree&#39;)
    self.grow_tree(data, categories, root, self.feature_names)  # adds to root
    self.tree_ = ET.tostring(root, encoding=&#34;unicode&#34;)
    # print(&#39;self.tree_&#39;, self.tree_)
    self.dom_ = minidom.parseString(self.tree_)
    return self</code></pre>
</details>
</dd>
<dt id="imodels.tree.c45_tree.c45_tree.C45TreeClassifier.grow_tree"><code class="name flex">
<span>def <span class="ident">grow_tree</span></span>(<span>self, X_t: List[list], y_str: List[str], parent, attrs_names)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>X_t</code></strong> :&ensp;<code>List[list]</code></dt>
<dd>input data transposed (num_features x num_observations)</dd>
<dt><strong><code>y_str</code></strong> :&ensp;<code>List[str]</code></dt>
<dd>outcome represented as strings</dd>
<dt><strong><code>parent</code></strong></dt>
<dd>&nbsp;</dd>
<dt><strong><code>attrs_names</code></strong></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def grow_tree(self, X_t: List[list], y_str: List[str], parent, attrs_names):
    &#34;&#34;&#34;
    Parameters
    ----------
    X_t: List[list]
        input data transposed (num_features x num_observations)
    y_str: List[str]
        outcome represented as strings

    parent
    attrs_names

    &#34;&#34;&#34;
    # check that y contains more than 1 distinct value
    if len(set(y_str)) &gt; 1:
        split = []

        # loop over features and build up potential splits
        for i in range(len(X_t)):
            if set(X_t[i]) == set(&#34;?&#34;):
                split.append(0)
            else:
                if is_numeric_feature(X_t[i]):
                    split.append(gain(y_str, X_t[i]))
                else:
                    split.append(gain_ratio(y_str, X_t[i]))

        # no good split, return child node
        if max(split) == 0:
            set_as_leaf_node(parent, y_str)

        # there is a good split
        else:
            index_selected = split.index(max(split))
            name_selected = str(attrs_names[index_selected])
            self.complexity_ += 1
            if is_numeric_feature(X_t[index_selected]):
                # split on this point
                split_point = get_best_split(y_str, X_t[index_selected])

                # build up children nodes
                r_child_X = [[] for i in range(len(X_t))]
                r_child_y = []
                l_child_X = [[] for i in range(len(X_t))]
                l_child_y = []
                for i in range(len(y_str)):
                    if not X_t[index_selected][i] == &#34;?&#34;:
                        if float(X_t[index_selected][i]) &lt; float(split_point):
                            l_child_y.append(y_str[i])
                            for j in range(len(X_t)):
                                l_child_X[j].append(X_t[j][i])
                        else:
                            r_child_y.append(y_str[i])
                            for j in range(len(X_t)):
                                r_child_X[j].append(X_t[j][i])

                # grow child nodes as well
                if len(l_child_y) &gt; 0 and len(r_child_y) &gt; 0 and (
                        self.max_rules is None or
                        self.complexity_ &lt;= self.max_rules
                ):
                    p_l = float(len(l_child_y)) / (len(X_t[index_selected]) - X_t[index_selected].count(&#34;?&#34;))
                    son = ET.SubElement(parent, name_selected,
                                        {&#39;feature&#39;: str(split_point), &#34;flag&#34;: &#34;l&#34;, &#34;p&#34;: str(round(p_l, 3))})
                    self.grow_tree(l_child_X, l_child_y, son, attrs_names)
                    son = ET.SubElement(parent, name_selected,
                                        {&#39;feature&#39;: str(split_point), &#34;flag&#34;: &#34;r&#34;, &#34;p&#34;: str(round(1 - p_l, 3))})
                    self.grow_tree(r_child_X, r_child_y, son, attrs_names)
                else:
                    num_max = 0
                    for cat in set(y_str):
                        num_cat = y_str.count(cat)
                        if num_cat &gt; num_max:
                            num_max = num_cat
                            most_cat = cat
                    parent.text = most_cat
            else:
                # split on non-numeric variable (e.g. categorical)
                # create a leaf for each unique value
                for k in set(X_t[index_selected]):
                    if not k == &#34;?&#34; and (
                            self.max_rules is None or
                            self.complexity_ &lt;= self.max_rules
                    ):
                        child_X = [[] for i in range(len(X_t))]
                        child_y = []
                        for i in range(len(y_str)):
                            if X_t[index_selected][i] == k:
                                child_y.append(y_str[i])
                                for j in range(len(X_t)):
                                    child_X[j].append(X_t[j][i])
                        son = ET.SubElement(parent, name_selected, {
                            &#39;feature&#39;: k, &#34;flag&#34;: &#34;m&#34;,
                            &#39;p&#39;: str(round(
                                float(len(child_y)) / (
                                        len(X_t[index_selected]) - X_t[index_selected].count(&#34;?&#34;)),
                                3))})
                        self.grow_tree(child_X, child_y, son, attrs_names)
    else:
        parent.text = y_str[0]</code></pre>
</details>
</dd>
<dt id="imodels.tree.c45_tree.c45_tree.C45TreeClassifier.impute_nodes"><code class="name flex">
<span>def <span class="ident">impute_nodes</span></span>(<span>self, X, y)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="returns">Returns</h2>
<dl>
<dt><code>the leaf by which this sample would be classified</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def impute_nodes(self, X, y):
    &#34;&#34;&#34;
    Returns
    ---
    the leaf by which this sample would be classified
    &#34;&#34;&#34;
    source_node = self.root
    for i in range(len(y)):
        sample, label = X[i, ...], y[i]
        _add_label(source_node, label)
        nodes = [source_node]
        while len(nodes) &gt; 0:
            node = nodes.pop()
            if not node.hasChildNodes():
                continue
            else:
                att_name = node.firstChild.nodeName
                if att_name != &#34;#text&#34;:
                    att = sample[self.feature_names.index(att_name)]
                    next_node = _get_next_node(node.childNodes, att)
                else:
                    next_node = node.firstChild
                _add_label(next_node, label)
                nodes.append(next_node)

    self._calc_probs(source_node)
    # self.dom_.childNodes[0] = source_node
    # self.tree_.source = source_node</code></pre>
</details>
</dd>
<dt id="imodels.tree.c45_tree.c45_tree.C45TreeClassifier.predict"><code class="name flex">
<span>def <span class="ident">predict</span></span>(<span>self, X)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict(self, X):
    raw_preds = self.raw_preds(X)
    return (raw_preds &gt; np.ones_like(raw_preds) * 0.5).astype(int)</code></pre>
</details>
</dd>
<dt id="imodels.tree.c45_tree.c45_tree.C45TreeClassifier.predict_proba"><code class="name flex">
<span>def <span class="ident">predict_proba</span></span>(<span>self, X)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict_proba(self, X):
    raw_preds = self.raw_preds(X)
    return np.vstack((1 - raw_preds, raw_preds)).transpose()</code></pre>
</details>
</dd>
<dt id="imodels.tree.c45_tree.c45_tree.C45TreeClassifier.raw_preds"><code class="name flex">
<span>def <span class="ident">raw_preds</span></span>(<span>self, X)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def raw_preds(self, X):
    check_is_fitted(self, [&#39;tree_&#39;, &#39;resultType&#39;, &#39;feature_names&#39;])
    X = check_array(X)
    if isinstance(X, pd.DataFrame):
        X = deepcopy(X)
        X.columns = self.feature_names
    root = self.root
    prediction = []
    for i in range(X.shape[0]):
        answerlist = decision(root, X[i], self.feature_names, 1)
        answerlist = sorted(answerlist.items(), key=lambda x: x[1], reverse=True)
        answer = answerlist[0][0]
        # prediction.append(self.resultType(answer))
        prediction.append(float(answer))

    return np.array(prediction)</code></pre>
</details>
</dd>
<dt id="imodels.tree.c45_tree.c45_tree.C45TreeClassifier.set_fit_request"><code class="name flex">
<span>def <span class="ident">set_fit_request</span></span>(<span>self: <a title="imodels.tree.c45_tree.c45_tree.C45TreeClassifier" href="#imodels.tree.c45_tree.c45_tree.C45TreeClassifier">C45TreeClassifier</a>, *, feature_names: Union[bool, ForwardRef(None), str] = '$UNCHANGED$') ‑> <a title="imodels.tree.c45_tree.c45_tree.C45TreeClassifier" href="#imodels.tree.c45_tree.c45_tree.C45TreeClassifier">C45TreeClassifier</a></span>
</code></dt>
<dd>
<div class="desc"><p>Request metadata passed to the <code>fit</code> method.</p>
<p>Note that this method is only relevant if
<code>enable_metadata_routing=True</code> (see :func:<code>sklearn.set_config</code>).
Please see :ref:<code>User Guide &lt;metadata_routing&gt;</code> on how the routing
mechanism works.</p>
<p>The options for each parameter are:</p>
<ul>
<li>
<p><code>True</code>: metadata is requested, and passed to <code>fit</code> if provided. The request is ignored if metadata is not provided.</p>
</li>
<li>
<p><code>False</code>: metadata is not requested and the meta-estimator will not pass it to <code>fit</code>.</p>
</li>
<li>
<p><code>None</code>: metadata is not requested, and the meta-estimator will raise an error if the user provides it.</p>
</li>
<li>
<p><code>str</code>: metadata should be passed to the meta-estimator with this given alias instead of the original name.</p>
</li>
</ul>
<p>The default (<code>sklearn.utils.metadata_routing.UNCHANGED</code>) retains the
existing request. This allows you to change the request for some
parameters and not others.</p>
<div class="admonition versionadded">
<p class="admonition-title">Added in version:&ensp;1.3</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method is only relevant if this estimator is used as a
sub-estimator of a meta-estimator, e.g. used inside a
:class:<code>pipeline.Pipeline</code>. Otherwise it has no effect.</p>
</div>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>feature_names</code></strong> :&ensp;<code>str, True, False,</code> or <code>None</code>,
default=<code>sklearn.utils.metadata_routing.UNCHANGED</code></dt>
<dd>Metadata routing for <code>feature_names</code> parameter in <code>fit</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>self</code></strong> :&ensp;<code>object</code></dt>
<dd>The updated object.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def func(**kw):
    &#34;&#34;&#34;Updates the request for provided parameters

    This docstring is overwritten below.
    See REQUESTER_DOC for expected functionality
    &#34;&#34;&#34;
    if not _routing_enabled():
        raise RuntimeError(
            &#34;This method is only available when metadata routing is enabled.&#34;
            &#34; You can enable it using&#34;
            &#34; sklearn.set_config(enable_metadata_routing=True).&#34;
        )

    if self.validate_keys and (set(kw) - set(self.keys)):
        raise TypeError(
            f&#34;Unexpected args: {set(kw) - set(self.keys)}. Accepted arguments&#34;
            f&#34; are: {set(self.keys)}&#34;
        )

    requests = instance._get_metadata_request()
    method_metadata_request = getattr(requests, self.name)

    for prop, alias in kw.items():
        if alias is not UNCHANGED:
            method_metadata_request.add_request(param=prop, alias=alias)
    instance._metadata_request = requests

    return instance</code></pre>
</details>
</dd>
<dt id="imodels.tree.c45_tree.c45_tree.C45TreeClassifier.set_score_request"><code class="name flex">
<span>def <span class="ident">set_score_request</span></span>(<span>self: <a title="imodels.tree.c45_tree.c45_tree.C45TreeClassifier" href="#imodels.tree.c45_tree.c45_tree.C45TreeClassifier">C45TreeClassifier</a>, *, sample_weight: Union[bool, ForwardRef(None), str] = '$UNCHANGED$') ‑> <a title="imodels.tree.c45_tree.c45_tree.C45TreeClassifier" href="#imodels.tree.c45_tree.c45_tree.C45TreeClassifier">C45TreeClassifier</a></span>
</code></dt>
<dd>
<div class="desc"><p>Request metadata passed to the <code>score</code> method.</p>
<p>Note that this method is only relevant if
<code>enable_metadata_routing=True</code> (see :func:<code>sklearn.set_config</code>).
Please see :ref:<code>User Guide &lt;metadata_routing&gt;</code> on how the routing
mechanism works.</p>
<p>The options for each parameter are:</p>
<ul>
<li>
<p><code>True</code>: metadata is requested, and passed to <code>score</code> if provided. The request is ignored if metadata is not provided.</p>
</li>
<li>
<p><code>False</code>: metadata is not requested and the meta-estimator will not pass it to <code>score</code>.</p>
</li>
<li>
<p><code>None</code>: metadata is not requested, and the meta-estimator will raise an error if the user provides it.</p>
</li>
<li>
<p><code>str</code>: metadata should be passed to the meta-estimator with this given alias instead of the original name.</p>
</li>
</ul>
<p>The default (<code>sklearn.utils.metadata_routing.UNCHANGED</code>) retains the
existing request. This allows you to change the request for some
parameters and not others.</p>
<div class="admonition versionadded">
<p class="admonition-title">Added in version:&ensp;1.3</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method is only relevant if this estimator is used as a
sub-estimator of a meta-estimator, e.g. used inside a
:class:<code>pipeline.Pipeline</code>. Otherwise it has no effect.</p>
</div>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>sample_weight</code></strong> :&ensp;<code>str, True, False,</code> or <code>None</code>,
default=<code>sklearn.utils.metadata_routing.UNCHANGED</code></dt>
<dd>Metadata routing for <code>sample_weight</code> parameter in <code>score</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>self</code></strong> :&ensp;<code>object</code></dt>
<dd>The updated object.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def func(**kw):
    &#34;&#34;&#34;Updates the request for provided parameters

    This docstring is overwritten below.
    See REQUESTER_DOC for expected functionality
    &#34;&#34;&#34;
    if not _routing_enabled():
        raise RuntimeError(
            &#34;This method is only available when metadata routing is enabled.&#34;
            &#34; You can enable it using&#34;
            &#34; sklearn.set_config(enable_metadata_routing=True).&#34;
        )

    if self.validate_keys and (set(kw) - set(self.keys)):
        raise TypeError(
            f&#34;Unexpected args: {set(kw) - set(self.keys)}. Accepted arguments&#34;
            f&#34; are: {set(self.keys)}&#34;
        )

    requests = instance._get_metadata_request()
    method_metadata_request = getattr(requests, self.name)

    for prop, alias in kw.items():
        if alias is not UNCHANGED:
            method_metadata_request.add_request(param=prop, alias=alias)
    instance._metadata_request = requests

    return instance</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="imodels.tree.c45_tree.c45_tree.HSC45TreeClassifier"><code class="flex name class">
<span>class <span class="ident">HSC45TreeClassifier</span></span>
<span>(</span><span>estimator_: <a title="imodels.tree.c45_tree.c45_tree.C45TreeClassifier" href="#imodels.tree.c45_tree.c45_tree.C45TreeClassifier">C45TreeClassifier</a>, reg_param: float = 1, shrinkage_scheme_: str = 'node_based')</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for all estimators in scikit-learn.</p>
<h2 id="notes">Notes</h2>
<p>All estimators should specify all the parameters that can be set
at the class level in their <code>__init__</code> as explicit keyword
arguments (no <code>*args</code> or <code>**kwargs</code>).</p>
<h2 id="params">Params</h2>
<p>reg_param: float
Higher is more regularization (can be arbitrarily large, should not be &lt; 0)</p>
<p>shrinkage_scheme: str
Experimental: Used to experiment with different forms of shrinkage. options are:
(i) node_based shrinks based on number of samples in parent node
(ii) leaf_based only shrinks leaf nodes based on number of leaf samples
(iii) constant shrinks every node by a constant lambda</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class HSC45TreeClassifier(BaseEstimator):
    def __init__(self, estimator_: C45TreeClassifier, reg_param: float = 1, shrinkage_scheme_: str = &#39;node_based&#39;):
        &#34;&#34;&#34;
        Params
        ------
        reg_param: float
            Higher is more regularization (can be arbitrarily large, should not be &lt; 0)

        shrinkage_scheme: str
            Experimental: Used to experiment with different forms of shrinkage. options are:
                (i) node_based shrinks based on number of samples in parent node
                (ii) leaf_based only shrinks leaf nodes based on number of leaf samples
                (iii) constant shrinks every node by a constant lambda
        &#34;&#34;&#34;
        super().__init__()
        self.reg_param = reg_param
        # print(&#39;est&#39;, estimator_)
        self.estimator_ = estimator_
        self.shrinkage_scheme_ = shrinkage_scheme_

    def _calc_probs(self, node):
        self.estimator_._calc_probs(node)

    def impute_nodes(self, X, y):
        self.estimator_.impute_nodes(X, y)

    def shrink_tree(self):
        shrink_node(self.estimator_.root, self.reg_param, None, None, 0, self.shrinkage_scheme_, 0)

    def predict_proba(self, X):
        return self.estimator_.predict_proba(X)

    def fit(self, *args, **kwargs):
        X = kwargs[&#39;X&#39;] if &#34;X&#34; in kwargs else args[0]
        y = kwargs[&#39;y&#39;] if &#34;y&#34; in kwargs else args[1]
        if not hasattr(self.estimator_, &#34;dom_&#34;):
            self.estimator_.fit(X, y)
        self.impute_nodes(X, y)
        self.shrink_tree()

    def predict(self, X):
        return self.estimator_.predict(X)

    @property
    def complexity_(self):
        return self.estimator_.complexity_</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>sklearn.base.BaseEstimator</li>
<li>sklearn.utils._metadata_requests._MetadataRequester</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="imodels.tree.c45_tree.c45_tree.HSC45TreeClassifierCV" href="#imodels.tree.c45_tree.c45_tree.HSC45TreeClassifierCV">HSC45TreeClassifierCV</a></li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="imodels.tree.c45_tree.c45_tree.HSC45TreeClassifier.complexity_"><code class="name">var <span class="ident">complexity_</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def complexity_(self):
    return self.estimator_.complexity_</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="imodels.tree.c45_tree.c45_tree.HSC45TreeClassifier.fit"><code class="name flex">
<span>def <span class="ident">fit</span></span>(<span>self, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fit(self, *args, **kwargs):
    X = kwargs[&#39;X&#39;] if &#34;X&#34; in kwargs else args[0]
    y = kwargs[&#39;y&#39;] if &#34;y&#34; in kwargs else args[1]
    if not hasattr(self.estimator_, &#34;dom_&#34;):
        self.estimator_.fit(X, y)
    self.impute_nodes(X, y)
    self.shrink_tree()</code></pre>
</details>
</dd>
<dt id="imodels.tree.c45_tree.c45_tree.HSC45TreeClassifier.impute_nodes"><code class="name flex">
<span>def <span class="ident">impute_nodes</span></span>(<span>self, X, y)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def impute_nodes(self, X, y):
    self.estimator_.impute_nodes(X, y)</code></pre>
</details>
</dd>
<dt id="imodels.tree.c45_tree.c45_tree.HSC45TreeClassifier.predict"><code class="name flex">
<span>def <span class="ident">predict</span></span>(<span>self, X)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict(self, X):
    return self.estimator_.predict(X)</code></pre>
</details>
</dd>
<dt id="imodels.tree.c45_tree.c45_tree.HSC45TreeClassifier.predict_proba"><code class="name flex">
<span>def <span class="ident">predict_proba</span></span>(<span>self, X)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict_proba(self, X):
    return self.estimator_.predict_proba(X)</code></pre>
</details>
</dd>
<dt id="imodels.tree.c45_tree.c45_tree.HSC45TreeClassifier.shrink_tree"><code class="name flex">
<span>def <span class="ident">shrink_tree</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def shrink_tree(self):
    shrink_node(self.estimator_.root, self.reg_param, None, None, 0, self.shrinkage_scheme_, 0)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="imodels.tree.c45_tree.c45_tree.HSC45TreeClassifierCV"><code class="flex name class">
<span>class <span class="ident">HSC45TreeClassifierCV</span></span>
<span>(</span><span>estimator_: <a title="imodels.tree.c45_tree.c45_tree.C45TreeClassifier" href="#imodels.tree.c45_tree.c45_tree.C45TreeClassifier">C45TreeClassifier</a>, reg_param_list: List[float] = [0.1, 1, 10, 50, 100, 500], shrinkage_scheme_: str = 'node_based', cv: int = 3, scoring='accuracy', *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for all estimators in scikit-learn.</p>
<h2 id="notes">Notes</h2>
<p>All estimators should specify all the parameters that can be set
at the class level in their <code>__init__</code> as explicit keyword
arguments (no <code>*args</code> or <code>**kwargs</code>).</p>
<p>Note: args, kwargs are not used but left so that imodels-experiments can still pass redundant args</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class HSC45TreeClassifierCV(HSC45TreeClassifier):
    def __init__(self, estimator_: C45TreeClassifier,
                 reg_param_list: List[float] = [0.1, 1, 10, 50, 100, 500], shrinkage_scheme_: str = &#39;node_based&#39;,
                 cv: int = 3, scoring=&#39;accuracy&#39;, *args, **kwargs):
        &#34;&#34;&#34;Note: args, kwargs are not used but left so that imodels-experiments can still pass redundant args
        &#34;&#34;&#34;
        super().__init__(estimator_, reg_param=None)
        self.reg_param_list = np.array(reg_param_list)
        self.cv = cv
        self.scoring = scoring
        self.shrinkage_scheme_ = shrinkage_scheme_
        # print(&#39;estimator&#39;, self.estimator_,
        #       &#39;checks.check_is_fitted(estimator)&#39;, checks.check_is_fitted(self.estimator_))
        # if checks.check_is_fitted(self.estimator_):
        #     raise Warning(&#39;Passed an already fitted estimator,&#39;
        #                   &#39;but shrinking not applied until fit method is called.&#39;)

    def fit(self, X, y, *args, **kwargs):
        self.scores_ = []

        for reg_param in self.reg_param_list:
            est = HSC45TreeClassifier(copy.deepcopy(self.estimator_), reg_param)
            cv_scores = cross_val_score(est, X, y, cv=self.cv, scoring=self.scoring)
            self.scores_.append(np.mean(cv_scores))
        self.reg_param = self.reg_param_list[np.argmax(self.scores_)]
        super().fit(X=X, y=y)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="imodels.tree.c45_tree.c45_tree.HSC45TreeClassifier" href="#imodels.tree.c45_tree.c45_tree.HSC45TreeClassifier">HSC45TreeClassifier</a></li>
<li>sklearn.base.BaseEstimator</li>
<li>sklearn.utils._metadata_requests._MetadataRequester</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="imodels.tree.c45_tree.c45_tree.HSC45TreeClassifierCV.fit"><code class="name flex">
<span>def <span class="ident">fit</span></span>(<span>self, X, y, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fit(self, X, y, *args, **kwargs):
    self.scores_ = []

    for reg_param in self.reg_param_list:
        est = HSC45TreeClassifier(copy.deepcopy(self.estimator_), reg_param)
        cv_scores = cross_val_score(est, X, y, cv=self.cv, scoring=self.scoring)
        self.scores_.append(np.mean(cv_scores))
    self.reg_param = self.reg_param_list[np.argmax(self.scores_)]
    super().fit(X=X, y=y)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index 🔍</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="imodels.tree.c45_tree" href="index.html">imodels.tree.c45_tree</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="imodels.tree.c45_tree.c45_tree.shrink_node" href="#imodels.tree.c45_tree.c45_tree.shrink_node">shrink_node</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="imodels.tree.c45_tree.c45_tree.C45TreeClassifier" href="#imodels.tree.c45_tree.c45_tree.C45TreeClassifier">C45TreeClassifier</a></code></h4>
<ul class="two-column">
<li><code><a title="imodels.tree.c45_tree.c45_tree.C45TreeClassifier.fit" href="#imodels.tree.c45_tree.c45_tree.C45TreeClassifier.fit">fit</a></code></li>
<li><code><a title="imodels.tree.c45_tree.c45_tree.C45TreeClassifier.grow_tree" href="#imodels.tree.c45_tree.c45_tree.C45TreeClassifier.grow_tree">grow_tree</a></code></li>
<li><code><a title="imodels.tree.c45_tree.c45_tree.C45TreeClassifier.impute_nodes" href="#imodels.tree.c45_tree.c45_tree.C45TreeClassifier.impute_nodes">impute_nodes</a></code></li>
<li><code><a title="imodels.tree.c45_tree.c45_tree.C45TreeClassifier.predict" href="#imodels.tree.c45_tree.c45_tree.C45TreeClassifier.predict">predict</a></code></li>
<li><code><a title="imodels.tree.c45_tree.c45_tree.C45TreeClassifier.predict_proba" href="#imodels.tree.c45_tree.c45_tree.C45TreeClassifier.predict_proba">predict_proba</a></code></li>
<li><code><a title="imodels.tree.c45_tree.c45_tree.C45TreeClassifier.raw_preds" href="#imodels.tree.c45_tree.c45_tree.C45TreeClassifier.raw_preds">raw_preds</a></code></li>
<li><code><a title="imodels.tree.c45_tree.c45_tree.C45TreeClassifier.root" href="#imodels.tree.c45_tree.c45_tree.C45TreeClassifier.root">root</a></code></li>
<li><code><a title="imodels.tree.c45_tree.c45_tree.C45TreeClassifier.set_fit_request" href="#imodels.tree.c45_tree.c45_tree.C45TreeClassifier.set_fit_request">set_fit_request</a></code></li>
<li><code><a title="imodels.tree.c45_tree.c45_tree.C45TreeClassifier.set_score_request" href="#imodels.tree.c45_tree.c45_tree.C45TreeClassifier.set_score_request">set_score_request</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="imodels.tree.c45_tree.c45_tree.HSC45TreeClassifier" href="#imodels.tree.c45_tree.c45_tree.HSC45TreeClassifier">HSC45TreeClassifier</a></code></h4>
<ul class="two-column">
<li><code><a title="imodels.tree.c45_tree.c45_tree.HSC45TreeClassifier.complexity_" href="#imodels.tree.c45_tree.c45_tree.HSC45TreeClassifier.complexity_">complexity_</a></code></li>
<li><code><a title="imodels.tree.c45_tree.c45_tree.HSC45TreeClassifier.fit" href="#imodels.tree.c45_tree.c45_tree.HSC45TreeClassifier.fit">fit</a></code></li>
<li><code><a title="imodels.tree.c45_tree.c45_tree.HSC45TreeClassifier.impute_nodes" href="#imodels.tree.c45_tree.c45_tree.HSC45TreeClassifier.impute_nodes">impute_nodes</a></code></li>
<li><code><a title="imodels.tree.c45_tree.c45_tree.HSC45TreeClassifier.predict" href="#imodels.tree.c45_tree.c45_tree.HSC45TreeClassifier.predict">predict</a></code></li>
<li><code><a title="imodels.tree.c45_tree.c45_tree.HSC45TreeClassifier.predict_proba" href="#imodels.tree.c45_tree.c45_tree.HSC45TreeClassifier.predict_proba">predict_proba</a></code></li>
<li><code><a title="imodels.tree.c45_tree.c45_tree.HSC45TreeClassifier.shrink_tree" href="#imodels.tree.c45_tree.c45_tree.HSC45TreeClassifier.shrink_tree">shrink_tree</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="imodels.tree.c45_tree.c45_tree.HSC45TreeClassifierCV" href="#imodels.tree.c45_tree.c45_tree.HSC45TreeClassifierCV">HSC45TreeClassifierCV</a></code></h4>
<ul class="">
<li><code><a title="imodels.tree.c45_tree.c45_tree.HSC45TreeClassifierCV.fit" href="#imodels.tree.c45_tree.c45_tree.HSC45TreeClassifierCV.fit">fit</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img align="center" width=100% src="https://csinva.io/imodels/img/anim.gif"> </img></p>
<!-- add wave animation -->
</nav>
</main>
<footer id="footer">
</footer>
</body>
</html>
<!-- add github corner -->
<a href="https://github.com/csinva/imodels" class="github-corner" aria-label="View source on GitHub"><svg width="120" height="120" viewBox="0 0 250 250" style="fill:#70B7FD; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="m128.3,109.0 c113.8,99.7 119.0,89.6 119.0,89.6 c122.0,82.7 120.5,78.6 120.5,78.6 c119.2,72.0 123.4,76.3 123.4,76.3 c127.3,80.9 125.5,87.3 125.5,87.3 c122.9,97.6 130.6,101.9 134.4,103.2" fill="currentcolor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
<!-- add wave animation stylesheet -->
<link rel="stylesheet" href="github.css">