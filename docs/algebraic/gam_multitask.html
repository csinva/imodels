<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from copy import deepcopy
import numpy as np
import pandas as pd
from sklearn.base import BaseEstimator
from sklearn.linear_model import ElasticNetCV, LinearRegression, RidgeCV, LassoCV
from sklearn.tree import DecisionTreeRegressor
from sklearn.utils.validation import check_is_fitted
from sklearn.utils import check_array
from sklearn.utils.multiclass import check_classification_targets
from sklearn.utils.validation import check_X_y
from sklearn.utils.validation import _check_sample_weight
from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor, AdaBoostClassifier, AdaBoostRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score
from tqdm import tqdm
from collections import defaultdict
import pandas as pd
import json
from sklearn.preprocessing import StandardScaler

import imodels
from interpret.glassbox import ExplainableBoostingClassifier, ExplainableBoostingRegressor

from sklearn.base import RegressorMixin, ClassifierMixin


# See notes in this implementation:
# https://github.com/interpretml/interpret/blob/develop/python/interpret-core/interpret/glassbox/_ebm/_ebm.py
# merge ebms: https://github.com/interpretml/interpret/blob/develop/python/interpret-core/interpret/glassbox/_ebm/_merge_ebms.py#L280

class MultiTaskGAM(BaseEstimator):
    &#34;&#34;&#34;Multi-task GAM classifier.
    &#34;&#34;&#34;

    def __init__(
        self,
        ebm_kwargs={&#39;n_jobs&#39;: 1},
        multitask=True,
        interactions=0.95,
        linear_penalty=&#39;ridge&#39;,
        onehot_prior=False,
        renormalize_features=False,
        random_state=42,
    ):
        &#34;&#34;&#34;
        Params
        ------
        Note: args override ebm_kwargs if there are duplicates
        one_hot_prior: bool
            If True and multitask, the linear model will be fit with a prior that the ebm
            features predicting the target should have coef 1
        &#34;&#34;&#34;
        self.ebm_kwargs = ebm_kwargs
        self.multitask = multitask
        self.linear_penalty = linear_penalty
        self.random_state = random_state
        self.interactions = interactions
        self.onehot_prior = onehot_prior
        self.renormalize_features = renormalize_features

        # override ebm_kwargs
        ebm_kwargs[&#39;random_state&#39;] = random_state
        ebm_kwargs[&#39;interactions&#39;] = interactions
        self.ebm_ = ExplainableBoostingRegressor(**(ebm_kwargs or {}))

    def fit(self, X, y, sample_weight=None):
        X, y = check_X_y(X, y, accept_sparse=False, multi_output=False)
        if isinstance(self, ClassifierMixin):
            check_classification_targets(y)
            self.classes_, y = np.unique(y, return_inverse=True)
        sample_weight = _check_sample_weight(sample_weight, X, dtype=None)

        # just fit normal ebm
        if not self.multitask:
            self.ebm_.fit(X, y, sample_weight=sample_weight)
            return self

        # fit EBM to each column of X
        self.ebms_ = []
        num_features = X.shape[1]
        for task_num in tqdm(range(num_features)):
            self.ebms_.append(deepcopy(self.ebm_))
            y_ = np.ascontiguousarray(X[:, task_num])
            X_ = deepcopy(X)
            X_[:, task_num] = 0
            self.ebms_[task_num].fit(X_, y_, sample_weight=sample_weight)

        # finally, fit EBM to the target
        self.ebms_.append(deepcopy(self.ebm_))
        self.ebms_[num_features].fit(X, y, sample_weight=sample_weight)

        # extract features
        self.term_names_list_ = [
            ebm_.term_names_ for ebm_ in self.ebms_]
        self.term_names_ = sum(self.term_names_list_, [])
        feats = self._extract_ebm_features(X)

        if self.renormalize_features:
            self.scaler_ = StandardScaler()
            feats = self.scaler_.fit_transform(feats)

        # fit a linear model to the features
        if self.linear_penalty == &#39;ridge&#39;:
            self.lin_model = RidgeCV(alphas=np.logspace(-2, 3, 7))
        elif self.linear_penalty == &#39;elasticnet&#39;:
            self.lin_model = ElasticNetCV(n_alphas=7)
        elif self.linear_penalty == &#39;lasso&#39;:
            self.lin_model = LassoCV(n_alphas=7)

        if self.onehot_prior:
            coef_prior_ = np.zeros((feats.shape[1], ))
            coef_prior_[:num_features] = 1
            preds_prior = feats @ coef_prior_
            residuals = y - preds_prior
            self.lin_model.fit(feats, residuals, sample_weight=sample_weight)
            self.lin_model.coef_ = self.lin_model.coef_ + coef_prior_

        else:
            self.lin_model.fit(feats, y, sample_weight=sample_weight)

        return self

    def _extract_ebm_features(self, X):
        &#39;&#39;&#39;
        Extract features by extracting all terms with EBM
        &#39;&#39;&#39;
        feats = np.empty((X.shape[0], len(self.term_names_)))
        offset = 0
        for ebm_num in range(len(self.ebms_)):
            # see eval_terms function: https://interpret.ml/docs/python/api/ExplainableBoostingRegressor.html#interpret.glassbox.ExplainableBoostingRegressor.eval_terms
            n_features_ebm_num = len(self.term_names_list_[ebm_num])
            feats[:, offset: offset + n_features_ebm_num] = \
                self.ebms_[ebm_num].eval_terms(X)
            offset += n_features_ebm_num

        return feats

    def predict(self, X):
        check_is_fitted(self)
        X = check_array(X, accept_sparse=False)
        if hasattr(self, &#39;ebms_&#39;):
            feats = self._extract_ebm_features(X)
            if hasattr(self, &#39;scaler_&#39;):
                feats = self.scaler_.transform(feats)
            return self.lin_model.predict(feats)
        else:
            return self.ebm_.predict(X)

    # def predict_proba(self, X):
    #     check_is_fitted(self)
    #     X = check_array(X, accept_sparse=False)
    #     return self.ebm_.predict_proba(X)


class MultiTaskGAMRegressor(MultiTaskGAM, RegressorMixin):
    ...


class MultiTaskGAMClassifier(MultiTaskGAM, ClassifierMixin):
    ...


def test_multitask_extraction():
    X, y, feature_names = imodels.get_clean_dataset(&#34;california_housing&#34;)
    # X, y, feature_names = imodels.get_clean_dataset(&#34;bike_sharing&#34;)

    # remove some features to speed things up
    X = X[:10, :4]
    y = y[:10]
    X, X_test, y_train, y_test = train_test_split(X, y, random_state=42)

    # unit test
    gam = MultiTaskGAMRegressor(multitask=False)
    gam.fit(X, y_train)
    gam2 = MultiTaskGAMRegressor(multitask=True)
    gam2.fit(X, y_train)
    preds_orig = gam.predict(X_test)
    assert np.allclose(preds_orig, gam2.ebms_[-1].predict(X_test))

    # extracted curves + intercept should sum to original predictions
    feats_extracted = gam2._extract_ebm_features(X_test)

    # get features for ebm that predicts target
    feats_extracted_target = feats_extracted[:,
                                             -len(gam2.term_names_list_[-1]):]
    # assert feats_extracted_target.shape == (num_samples, num_features)
    preds_extracted_target = np.sum(feats_extracted_target, axis=1) + \
        gam2.ebms_[-1].intercept_
    diff = preds_extracted_target - preds_orig
    assert np.allclose(preds_extracted_target, preds_orig), diff
    print(&#39;Tests pass successfully&#39;)


if __name__ == &#34;__main__&#34;:
    # test_multitask_extraction()
    # X, y, feature_names = imodels.get_clean_dataset(&#34;heart&#34;)
    X, y, feature_names = imodels.get_clean_dataset(&#34;bike_sharing&#34;)
    # X, y, feature_names = imodels.get_clean_dataset(&#34;diabetes&#34;)

    # remove some features to speed things up
    X = X[:, :2]
    X, X_test, y_train, y_test = train_test_split(X, y, random_state=42)

    kwargs = dict(
        random_state=42,
    )
    results = defaultdict(list)
    for gam in tqdm([
            # AdaBoostRegressor(estimator=MultiTaskGAMRegressor(
        # multitask=True), n_estimators=2),
        # MultiTaskGAMRegressor(multitask=True, onehot_prior=True),
        # MultiTaskGAMRegressor(multitask=True, onehot_prior=False),
        MultiTaskGAMRegressor(multitask=True, renormalize_features=True),
        MultiTaskGAMRegressor(multitask=True, renormalize_features=False),
        # ExplainableBoostingRegressor(n_jobs=1, interactions=0)
    ]):
        np.random.seed(42)
        results[&#34;model_name&#34;].append(gam)
        print(&#39;Fitting&#39;, results[&#39;model_name&#39;][-1])
        gam.fit(X, y_train)
        results[&#39;test_corr&#39;].append(np.corrcoef(
            y_test, gam.predict(X_test))[0, 1].round(3))
        results[&#39;test_r2&#39;].append(gam.score(X_test, y_test).round(3))
        if hasattr(gam, &#39;lin_model&#39;):
            print(&#39;lin model coef&#39;, gam.lin_model.coef_)

    # don&#39;t round strings
    with pd.option_context(
        &#34;display.max_rows&#34;, None, &#34;display.max_columns&#34;, None, &#34;display.width&#34;, 1000
    ):
        print(pd.DataFrame(results).round(3))</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="imodels.algebraic.gam_multitask.test_multitask_extraction"><code class="name flex">
<span>def <span class="ident">test_multitask_extraction</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def test_multitask_extraction():
    X, y, feature_names = imodels.get_clean_dataset(&#34;california_housing&#34;)
    # X, y, feature_names = imodels.get_clean_dataset(&#34;bike_sharing&#34;)

    # remove some features to speed things up
    X = X[:10, :4]
    y = y[:10]
    X, X_test, y_train, y_test = train_test_split(X, y, random_state=42)

    # unit test
    gam = MultiTaskGAMRegressor(multitask=False)
    gam.fit(X, y_train)
    gam2 = MultiTaskGAMRegressor(multitask=True)
    gam2.fit(X, y_train)
    preds_orig = gam.predict(X_test)
    assert np.allclose(preds_orig, gam2.ebms_[-1].predict(X_test))

    # extracted curves + intercept should sum to original predictions
    feats_extracted = gam2._extract_ebm_features(X_test)

    # get features for ebm that predicts target
    feats_extracted_target = feats_extracted[:,
                                             -len(gam2.term_names_list_[-1]):]
    # assert feats_extracted_target.shape == (num_samples, num_features)
    preds_extracted_target = np.sum(feats_extracted_target, axis=1) + \
        gam2.ebms_[-1].intercept_
    diff = preds_extracted_target - preds_orig
    assert np.allclose(preds_extracted_target, preds_orig), diff
    print(&#39;Tests pass successfully&#39;)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="imodels.algebraic.gam_multitask.MultiTaskGAM"><code class="flex name class">
<span>class <span class="ident">MultiTaskGAM</span></span>
<span>(</span><span>ebm_kwargs={'n_jobs': 1}, multitask=True, interactions=0.95, linear_penalty='ridge', onehot_prior=False, renormalize_features=False, random_state=42)</span>
</code></dt>
<dd>
<div class="desc"><p>Multi-task GAM classifier.</p>
<h2 id="params">Params</h2>
<p>Note: args override ebm_kwargs if there are duplicates
one_hot_prior: bool
If True and multitask, the linear model will be fit with a prior that the ebm
features predicting the target should have coef 1</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class MultiTaskGAM(BaseEstimator):
    &#34;&#34;&#34;Multi-task GAM classifier.
    &#34;&#34;&#34;

    def __init__(
        self,
        ebm_kwargs={&#39;n_jobs&#39;: 1},
        multitask=True,
        interactions=0.95,
        linear_penalty=&#39;ridge&#39;,
        onehot_prior=False,
        renormalize_features=False,
        random_state=42,
    ):
        &#34;&#34;&#34;
        Params
        ------
        Note: args override ebm_kwargs if there are duplicates
        one_hot_prior: bool
            If True and multitask, the linear model will be fit with a prior that the ebm
            features predicting the target should have coef 1
        &#34;&#34;&#34;
        self.ebm_kwargs = ebm_kwargs
        self.multitask = multitask
        self.linear_penalty = linear_penalty
        self.random_state = random_state
        self.interactions = interactions
        self.onehot_prior = onehot_prior
        self.renormalize_features = renormalize_features

        # override ebm_kwargs
        ebm_kwargs[&#39;random_state&#39;] = random_state
        ebm_kwargs[&#39;interactions&#39;] = interactions
        self.ebm_ = ExplainableBoostingRegressor(**(ebm_kwargs or {}))

    def fit(self, X, y, sample_weight=None):
        X, y = check_X_y(X, y, accept_sparse=False, multi_output=False)
        if isinstance(self, ClassifierMixin):
            check_classification_targets(y)
            self.classes_, y = np.unique(y, return_inverse=True)
        sample_weight = _check_sample_weight(sample_weight, X, dtype=None)

        # just fit normal ebm
        if not self.multitask:
            self.ebm_.fit(X, y, sample_weight=sample_weight)
            return self

        # fit EBM to each column of X
        self.ebms_ = []
        num_features = X.shape[1]
        for task_num in tqdm(range(num_features)):
            self.ebms_.append(deepcopy(self.ebm_))
            y_ = np.ascontiguousarray(X[:, task_num])
            X_ = deepcopy(X)
            X_[:, task_num] = 0
            self.ebms_[task_num].fit(X_, y_, sample_weight=sample_weight)

        # finally, fit EBM to the target
        self.ebms_.append(deepcopy(self.ebm_))
        self.ebms_[num_features].fit(X, y, sample_weight=sample_weight)

        # extract features
        self.term_names_list_ = [
            ebm_.term_names_ for ebm_ in self.ebms_]
        self.term_names_ = sum(self.term_names_list_, [])
        feats = self._extract_ebm_features(X)

        if self.renormalize_features:
            self.scaler_ = StandardScaler()
            feats = self.scaler_.fit_transform(feats)

        # fit a linear model to the features
        if self.linear_penalty == &#39;ridge&#39;:
            self.lin_model = RidgeCV(alphas=np.logspace(-2, 3, 7))
        elif self.linear_penalty == &#39;elasticnet&#39;:
            self.lin_model = ElasticNetCV(n_alphas=7)
        elif self.linear_penalty == &#39;lasso&#39;:
            self.lin_model = LassoCV(n_alphas=7)

        if self.onehot_prior:
            coef_prior_ = np.zeros((feats.shape[1], ))
            coef_prior_[:num_features] = 1
            preds_prior = feats @ coef_prior_
            residuals = y - preds_prior
            self.lin_model.fit(feats, residuals, sample_weight=sample_weight)
            self.lin_model.coef_ = self.lin_model.coef_ + coef_prior_

        else:
            self.lin_model.fit(feats, y, sample_weight=sample_weight)

        return self

    def _extract_ebm_features(self, X):
        &#39;&#39;&#39;
        Extract features by extracting all terms with EBM
        &#39;&#39;&#39;
        feats = np.empty((X.shape[0], len(self.term_names_)))
        offset = 0
        for ebm_num in range(len(self.ebms_)):
            # see eval_terms function: https://interpret.ml/docs/python/api/ExplainableBoostingRegressor.html#interpret.glassbox.ExplainableBoostingRegressor.eval_terms
            n_features_ebm_num = len(self.term_names_list_[ebm_num])
            feats[:, offset: offset + n_features_ebm_num] = \
                self.ebms_[ebm_num].eval_terms(X)
            offset += n_features_ebm_num

        return feats

    def predict(self, X):
        check_is_fitted(self)
        X = check_array(X, accept_sparse=False)
        if hasattr(self, &#39;ebms_&#39;):
            feats = self._extract_ebm_features(X)
            if hasattr(self, &#39;scaler_&#39;):
                feats = self.scaler_.transform(feats)
            return self.lin_model.predict(feats)
        else:
            return self.ebm_.predict(X)

    # def predict_proba(self, X):
    #     check_is_fitted(self)
    #     X = check_array(X, accept_sparse=False)
    #     return self.ebm_.predict_proba(X)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>sklearn.base.BaseEstimator</li>
<li>sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin</li>
<li>sklearn.utils._metadata_requests._MetadataRequester</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="imodels.algebraic.gam_multitask.MultiTaskGAMClassifier" href="#imodels.algebraic.gam_multitask.MultiTaskGAMClassifier">MultiTaskGAMClassifier</a></li>
<li><a title="imodels.algebraic.gam_multitask.MultiTaskGAMRegressor" href="#imodels.algebraic.gam_multitask.MultiTaskGAMRegressor">MultiTaskGAMRegressor</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="imodels.algebraic.gam_multitask.MultiTaskGAM.fit"><code class="name flex">
<span>def <span class="ident">fit</span></span>(<span>self, X, y, sample_weight=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fit(self, X, y, sample_weight=None):
    X, y = check_X_y(X, y, accept_sparse=False, multi_output=False)
    if isinstance(self, ClassifierMixin):
        check_classification_targets(y)
        self.classes_, y = np.unique(y, return_inverse=True)
    sample_weight = _check_sample_weight(sample_weight, X, dtype=None)

    # just fit normal ebm
    if not self.multitask:
        self.ebm_.fit(X, y, sample_weight=sample_weight)
        return self

    # fit EBM to each column of X
    self.ebms_ = []
    num_features = X.shape[1]
    for task_num in tqdm(range(num_features)):
        self.ebms_.append(deepcopy(self.ebm_))
        y_ = np.ascontiguousarray(X[:, task_num])
        X_ = deepcopy(X)
        X_[:, task_num] = 0
        self.ebms_[task_num].fit(X_, y_, sample_weight=sample_weight)

    # finally, fit EBM to the target
    self.ebms_.append(deepcopy(self.ebm_))
    self.ebms_[num_features].fit(X, y, sample_weight=sample_weight)

    # extract features
    self.term_names_list_ = [
        ebm_.term_names_ for ebm_ in self.ebms_]
    self.term_names_ = sum(self.term_names_list_, [])
    feats = self._extract_ebm_features(X)

    if self.renormalize_features:
        self.scaler_ = StandardScaler()
        feats = self.scaler_.fit_transform(feats)

    # fit a linear model to the features
    if self.linear_penalty == &#39;ridge&#39;:
        self.lin_model = RidgeCV(alphas=np.logspace(-2, 3, 7))
    elif self.linear_penalty == &#39;elasticnet&#39;:
        self.lin_model = ElasticNetCV(n_alphas=7)
    elif self.linear_penalty == &#39;lasso&#39;:
        self.lin_model = LassoCV(n_alphas=7)

    if self.onehot_prior:
        coef_prior_ = np.zeros((feats.shape[1], ))
        coef_prior_[:num_features] = 1
        preds_prior = feats @ coef_prior_
        residuals = y - preds_prior
        self.lin_model.fit(feats, residuals, sample_weight=sample_weight)
        self.lin_model.coef_ = self.lin_model.coef_ + coef_prior_

    else:
        self.lin_model.fit(feats, y, sample_weight=sample_weight)

    return self</code></pre>
</details>
</dd>
<dt id="imodels.algebraic.gam_multitask.MultiTaskGAM.predict"><code class="name flex">
<span>def <span class="ident">predict</span></span>(<span>self, X)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict(self, X):
    check_is_fitted(self)
    X = check_array(X, accept_sparse=False)
    if hasattr(self, &#39;ebms_&#39;):
        feats = self._extract_ebm_features(X)
        if hasattr(self, &#39;scaler_&#39;):
            feats = self.scaler_.transform(feats)
        return self.lin_model.predict(feats)
    else:
        return self.ebm_.predict(X)</code></pre>
</details>
</dd>
<dt id="imodels.algebraic.gam_multitask.MultiTaskGAM.set_fit_request"><code class="name flex">
<span>def <span class="ident">set_fit_request</span></span>(<span>self:¬†<a title="imodels.algebraic.gam_multitask.MultiTaskGAM" href="#imodels.algebraic.gam_multitask.MultiTaskGAM">MultiTaskGAM</a>, *, sample_weight:¬†Union[bool,¬†ForwardRef(None),¬†str]¬†=¬†'$UNCHANGED$') ‚Äë>¬†<a title="imodels.algebraic.gam_multitask.MultiTaskGAM" href="#imodels.algebraic.gam_multitask.MultiTaskGAM">MultiTaskGAM</a></span>
</code></dt>
<dd>
<div class="desc"><p>Request metadata passed to the <code>fit</code> method.</p>
<p>Note that this method is only relevant if
<code>enable_metadata_routing=True</code> (see :func:<code>sklearn.set_config</code>).
Please see :ref:<code>User Guide &lt;metadata_routing&gt;</code> on how the routing
mechanism works.</p>
<p>The options for each parameter are:</p>
<ul>
<li>
<p><code>True</code>: metadata is requested, and passed to <code>fit</code> if provided. The request is ignored if metadata is not provided.</p>
</li>
<li>
<p><code>False</code>: metadata is not requested and the meta-estimator will not pass it to <code>fit</code>.</p>
</li>
<li>
<p><code>None</code>: metadata is not requested, and the meta-estimator will raise an error if the user provides it.</p>
</li>
<li>
<p><code>str</code>: metadata should be passed to the meta-estimator with this given alias instead of the original name.</p>
</li>
</ul>
<p>The default (<code>sklearn.utils.metadata_routing.UNCHANGED</code>) retains the
existing request. This allows you to change the request for some
parameters and not others.</p>
<div class="admonition versionadded">
<p class="admonition-title">Added in version:&ensp;1.3</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method is only relevant if this estimator is used as a
sub-estimator of a meta-estimator, e.g. used inside a
:class:<code>~sklearn.pipeline.Pipeline</code>. Otherwise it has no effect.</p>
</div>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>sample_weight</code></strong> :&ensp;<code>str, True, False,</code> or <code>None</code>,
default=<code>sklearn.utils.metadata_routing.UNCHANGED</code></dt>
<dd>Metadata routing for <code>sample_weight</code> parameter in <code>fit</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>self</code></strong> :&ensp;<code>object</code></dt>
<dd>The updated object.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def func(**kw):
    &#34;&#34;&#34;Updates the request for provided parameters

    This docstring is overwritten below.
    See REQUESTER_DOC for expected functionality
    &#34;&#34;&#34;
    if not _routing_enabled():
        raise RuntimeError(
            &#34;This method is only available when metadata routing is enabled.&#34;
            &#34; You can enable it using&#34;
            &#34; sklearn.set_config(enable_metadata_routing=True).&#34;
        )

    if self.validate_keys and (set(kw) - set(self.keys)):
        raise TypeError(
            f&#34;Unexpected args: {set(kw) - set(self.keys)}. Accepted arguments&#34;
            f&#34; are: {set(self.keys)}&#34;
        )

    requests = instance._get_metadata_request()
    method_metadata_request = getattr(requests, self.name)

    for prop, alias in kw.items():
        if alias is not UNCHANGED:
            method_metadata_request.add_request(param=prop, alias=alias)
    instance._metadata_request = requests

    return instance</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="imodels.algebraic.gam_multitask.MultiTaskGAMClassifier"><code class="flex name class">
<span>class <span class="ident">MultiTaskGAMClassifier</span></span>
<span>(</span><span>ebm_kwargs={'n_jobs': 1}, multitask=True, interactions=0.95, linear_penalty='ridge', onehot_prior=False, renormalize_features=False, random_state=42)</span>
</code></dt>
<dd>
<div class="desc"><p>Multi-task GAM classifier.</p>
<h2 id="params">Params</h2>
<p>Note: args override ebm_kwargs if there are duplicates
one_hot_prior: bool
If True and multitask, the linear model will be fit with a prior that the ebm
features predicting the target should have coef 1</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class MultiTaskGAMClassifier(MultiTaskGAM, ClassifierMixin):
    ...</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="imodels.algebraic.gam_multitask.MultiTaskGAM" href="#imodels.algebraic.gam_multitask.MultiTaskGAM">MultiTaskGAM</a></li>
<li>sklearn.base.BaseEstimator</li>
<li>sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin</li>
<li>sklearn.utils._metadata_requests._MetadataRequester</li>
<li>sklearn.base.ClassifierMixin</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="imodels.algebraic.gam_multitask.MultiTaskGAMClassifier.set_score_request"><code class="name flex">
<span>def <span class="ident">set_score_request</span></span>(<span>self:¬†<a title="imodels.algebraic.gam_multitask.MultiTaskGAMClassifier" href="#imodels.algebraic.gam_multitask.MultiTaskGAMClassifier">MultiTaskGAMClassifier</a>, *, sample_weight:¬†Union[bool,¬†ForwardRef(None),¬†str]¬†=¬†'$UNCHANGED$') ‚Äë>¬†<a title="imodels.algebraic.gam_multitask.MultiTaskGAMClassifier" href="#imodels.algebraic.gam_multitask.MultiTaskGAMClassifier">MultiTaskGAMClassifier</a></span>
</code></dt>
<dd>
<div class="desc"><p>Request metadata passed to the <code>score</code> method.</p>
<p>Note that this method is only relevant if
<code>enable_metadata_routing=True</code> (see :func:<code>sklearn.set_config</code>).
Please see :ref:<code>User Guide &lt;metadata_routing&gt;</code> on how the routing
mechanism works.</p>
<p>The options for each parameter are:</p>
<ul>
<li>
<p><code>True</code>: metadata is requested, and passed to <code>score</code> if provided. The request is ignored if metadata is not provided.</p>
</li>
<li>
<p><code>False</code>: metadata is not requested and the meta-estimator will not pass it to <code>score</code>.</p>
</li>
<li>
<p><code>None</code>: metadata is not requested, and the meta-estimator will raise an error if the user provides it.</p>
</li>
<li>
<p><code>str</code>: metadata should be passed to the meta-estimator with this given alias instead of the original name.</p>
</li>
</ul>
<p>The default (<code>sklearn.utils.metadata_routing.UNCHANGED</code>) retains the
existing request. This allows you to change the request for some
parameters and not others.</p>
<div class="admonition versionadded">
<p class="admonition-title">Added in version:&ensp;1.3</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method is only relevant if this estimator is used as a
sub-estimator of a meta-estimator, e.g. used inside a
:class:<code>~sklearn.pipeline.Pipeline</code>. Otherwise it has no effect.</p>
</div>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>sample_weight</code></strong> :&ensp;<code>str, True, False,</code> or <code>None</code>,
default=<code>sklearn.utils.metadata_routing.UNCHANGED</code></dt>
<dd>Metadata routing for <code>sample_weight</code> parameter in <code>score</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>self</code></strong> :&ensp;<code>object</code></dt>
<dd>The updated object.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def func(**kw):
    &#34;&#34;&#34;Updates the request for provided parameters

    This docstring is overwritten below.
    See REQUESTER_DOC for expected functionality
    &#34;&#34;&#34;
    if not _routing_enabled():
        raise RuntimeError(
            &#34;This method is only available when metadata routing is enabled.&#34;
            &#34; You can enable it using&#34;
            &#34; sklearn.set_config(enable_metadata_routing=True).&#34;
        )

    if self.validate_keys and (set(kw) - set(self.keys)):
        raise TypeError(
            f&#34;Unexpected args: {set(kw) - set(self.keys)}. Accepted arguments&#34;
            f&#34; are: {set(self.keys)}&#34;
        )

    requests = instance._get_metadata_request()
    method_metadata_request = getattr(requests, self.name)

    for prop, alias in kw.items():
        if alias is not UNCHANGED:
            method_metadata_request.add_request(param=prop, alias=alias)
    instance._metadata_request = requests

    return instance</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="imodels.algebraic.gam_multitask.MultiTaskGAM" href="#imodels.algebraic.gam_multitask.MultiTaskGAM">MultiTaskGAM</a></b></code>:
<ul class="hlist">
<li><code><a title="imodels.algebraic.gam_multitask.MultiTaskGAM.set_fit_request" href="#imodels.algebraic.gam_multitask.MultiTaskGAM.set_fit_request">set_fit_request</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="imodels.algebraic.gam_multitask.MultiTaskGAMRegressor"><code class="flex name class">
<span>class <span class="ident">MultiTaskGAMRegressor</span></span>
<span>(</span><span>ebm_kwargs={'n_jobs': 1}, multitask=True, interactions=0.95, linear_penalty='ridge', onehot_prior=False, renormalize_features=False, random_state=42)</span>
</code></dt>
<dd>
<div class="desc"><p>Multi-task GAM classifier.</p>
<h2 id="params">Params</h2>
<p>Note: args override ebm_kwargs if there are duplicates
one_hot_prior: bool
If True and multitask, the linear model will be fit with a prior that the ebm
features predicting the target should have coef 1</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class MultiTaskGAMRegressor(MultiTaskGAM, RegressorMixin):
    ...</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="imodels.algebraic.gam_multitask.MultiTaskGAM" href="#imodels.algebraic.gam_multitask.MultiTaskGAM">MultiTaskGAM</a></li>
<li>sklearn.base.BaseEstimator</li>
<li>sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin</li>
<li>sklearn.utils._metadata_requests._MetadataRequester</li>
<li>sklearn.base.RegressorMixin</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="imodels.algebraic.gam_multitask.MultiTaskGAMRegressor.set_score_request"><code class="name flex">
<span>def <span class="ident">set_score_request</span></span>(<span>self:¬†<a title="imodels.algebraic.gam_multitask.MultiTaskGAMRegressor" href="#imodels.algebraic.gam_multitask.MultiTaskGAMRegressor">MultiTaskGAMRegressor</a>, *, sample_weight:¬†Union[bool,¬†ForwardRef(None),¬†str]¬†=¬†'$UNCHANGED$') ‚Äë>¬†<a title="imodels.algebraic.gam_multitask.MultiTaskGAMRegressor" href="#imodels.algebraic.gam_multitask.MultiTaskGAMRegressor">MultiTaskGAMRegressor</a></span>
</code></dt>
<dd>
<div class="desc"><p>Request metadata passed to the <code>score</code> method.</p>
<p>Note that this method is only relevant if
<code>enable_metadata_routing=True</code> (see :func:<code>sklearn.set_config</code>).
Please see :ref:<code>User Guide &lt;metadata_routing&gt;</code> on how the routing
mechanism works.</p>
<p>The options for each parameter are:</p>
<ul>
<li>
<p><code>True</code>: metadata is requested, and passed to <code>score</code> if provided. The request is ignored if metadata is not provided.</p>
</li>
<li>
<p><code>False</code>: metadata is not requested and the meta-estimator will not pass it to <code>score</code>.</p>
</li>
<li>
<p><code>None</code>: metadata is not requested, and the meta-estimator will raise an error if the user provides it.</p>
</li>
<li>
<p><code>str</code>: metadata should be passed to the meta-estimator with this given alias instead of the original name.</p>
</li>
</ul>
<p>The default (<code>sklearn.utils.metadata_routing.UNCHANGED</code>) retains the
existing request. This allows you to change the request for some
parameters and not others.</p>
<div class="admonition versionadded">
<p class="admonition-title">Added in version:&ensp;1.3</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method is only relevant if this estimator is used as a
sub-estimator of a meta-estimator, e.g. used inside a
:class:<code>~sklearn.pipeline.Pipeline</code>. Otherwise it has no effect.</p>
</div>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>sample_weight</code></strong> :&ensp;<code>str, True, False,</code> or <code>None</code>,
default=<code>sklearn.utils.metadata_routing.UNCHANGED</code></dt>
<dd>Metadata routing for <code>sample_weight</code> parameter in <code>score</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>self</code></strong> :&ensp;<code>object</code></dt>
<dd>The updated object.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def func(**kw):
    &#34;&#34;&#34;Updates the request for provided parameters

    This docstring is overwritten below.
    See REQUESTER_DOC for expected functionality
    &#34;&#34;&#34;
    if not _routing_enabled():
        raise RuntimeError(
            &#34;This method is only available when metadata routing is enabled.&#34;
            &#34; You can enable it using&#34;
            &#34; sklearn.set_config(enable_metadata_routing=True).&#34;
        )

    if self.validate_keys and (set(kw) - set(self.keys)):
        raise TypeError(
            f&#34;Unexpected args: {set(kw) - set(self.keys)}. Accepted arguments&#34;
            f&#34; are: {set(self.keys)}&#34;
        )

    requests = instance._get_metadata_request()
    method_metadata_request = getattr(requests, self.name)

    for prop, alias in kw.items():
        if alias is not UNCHANGED:
            method_metadata_request.add_request(param=prop, alias=alias)
    instance._metadata_request = requests

    return instance</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="imodels.algebraic.gam_multitask.MultiTaskGAM" href="#imodels.algebraic.gam_multitask.MultiTaskGAM">MultiTaskGAM</a></b></code>:
<ul class="hlist">
<li><code><a title="imodels.algebraic.gam_multitask.MultiTaskGAM.set_fit_request" href="#imodels.algebraic.gam_multitask.MultiTaskGAM.set_fit_request">set_fit_request</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index üîç</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="imodels.algebraic" href="index.html">imodels.algebraic</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="imodels.algebraic.gam_multitask.test_multitask_extraction" href="#imodels.algebraic.gam_multitask.test_multitask_extraction">test_multitask_extraction</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="imodels.algebraic.gam_multitask.MultiTaskGAM" href="#imodels.algebraic.gam_multitask.MultiTaskGAM">MultiTaskGAM</a></code></h4>
<ul class="">
<li><code><a title="imodels.algebraic.gam_multitask.MultiTaskGAM.fit" href="#imodels.algebraic.gam_multitask.MultiTaskGAM.fit">fit</a></code></li>
<li><code><a title="imodels.algebraic.gam_multitask.MultiTaskGAM.predict" href="#imodels.algebraic.gam_multitask.MultiTaskGAM.predict">predict</a></code></li>
<li><code><a title="imodels.algebraic.gam_multitask.MultiTaskGAM.set_fit_request" href="#imodels.algebraic.gam_multitask.MultiTaskGAM.set_fit_request">set_fit_request</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="imodels.algebraic.gam_multitask.MultiTaskGAMClassifier" href="#imodels.algebraic.gam_multitask.MultiTaskGAMClassifier">MultiTaskGAMClassifier</a></code></h4>
<ul class="">
<li><code><a title="imodels.algebraic.gam_multitask.MultiTaskGAMClassifier.set_score_request" href="#imodels.algebraic.gam_multitask.MultiTaskGAMClassifier.set_score_request">set_score_request</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="imodels.algebraic.gam_multitask.MultiTaskGAMRegressor" href="#imodels.algebraic.gam_multitask.MultiTaskGAMRegressor">MultiTaskGAMRegressor</a></code></h4>
<ul class="">
<li><code><a title="imodels.algebraic.gam_multitask.MultiTaskGAMRegressor.set_score_request" href="#imodels.algebraic.gam_multitask.MultiTaskGAMRegressor.set_score_request">set_score_request</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img align="center" width=100% src="https://csinva.io/imodels/img/anim.gif"> </img></p>
<!-- add wave animation -->
</nav>
</main>
<footer id="footer">
</footer>
</body>
</html>
<!-- add github corner -->
<a href="https://github.com/csinva/imodels" class="github-corner" aria-label="View source on GitHub"><svg width="120" height="120" viewBox="0 0 250 250" style="fill:#70B7FD; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="m128.3,109.0 c113.8,99.7 119.0,89.6 119.0,89.6 c122.0,82.7 120.5,78.6 120.5,78.6 c119.2,72.0 123.4,76.3 123.4,76.3 c127.3,80.9 125.5,87.3 125.5,87.3 c122.9,97.6 130.6,101.9 134.4,103.2" fill="currentcolor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
<!-- add wave animation stylesheet -->
<link rel="stylesheet" href="github.css">